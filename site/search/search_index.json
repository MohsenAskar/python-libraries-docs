{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Python Libraries by Mohsen Askar","text":"<p>Welcome to the documentation hub for my Python libraries. Here you'll find comprehensive documentation for:</p>"},{"location":"#modularity-encoding","title":"Modularity Encoding","text":"<p><code>modularity_encoding</code> package provides functionality for grouping high dimensional Health Coding Systems (HCSs),such as ICD and ATC codes, in Machine Learning Models and similar applications.</p> <p>PyPi address: https://pypi.org/project/modularity-encoding/</p>"},{"location":"#stata-codebook","title":"Stata Codebook","text":"<p><code>stata_codebook</code> provides tools for generating detailed descriptive statistics and summaries of data frames, similar to Stata's <code>codebook</code> command.</p> <p>PyPi address: https://pypi.org/project/stata-codebook/</p>"},{"location":"#my-dataviewer-gui","title":"My DataViewer GUI","text":"<p><code>mydataViewer_GUI</code> is a Lightweight Real-Time Interactive Data Viewer IDE for Python inspired by the Stata <code>browser</code> command.</p> <p>PyPi address: https://pypi.org/project/mydataviewer-GUI/</p>"},{"location":"#assumption-sheriff","title":"Assumption Sheriff","text":"<p><code>AssumptionSheriff</code> is a comprehensive Python package designed to automatically validate statistical tests' assumptions.</p> <p>PyPi address: https://pypi.org/project/assumption-sheriff/</p>"},{"location":"#data-insightron","title":"Data Insightron","text":"<p><code>DataInsightron</code> is a Python package designed to provide a comprehensive overview of a dataset characteristics.</p> <p>PyPi address: https://pypi.org/project/data_insightron/</p>"},{"location":"#audio2topics","title":"Audio2Topics","text":"<p><code>Audio2Topics</code> is a Python package to automatically extract topics' suggstions from voice/text files.</p> <p>PyPi address: https://pypi.org/project/audio2topics/</p> <p>Each library's documentation includes:</p> <ul> <li>Getting started guide</li> <li>Usage examples</li> <li>Related information</li> </ul> <p>Stay tuned for more packages! \ud83d\ude42</p>"},{"location":"assumption_sheriff/","title":"Overview","text":""},{"location":"assumption_sheriff/#assumption-sheriff-package","title":"<code>Assumption Sheriff</code> Package \ud83d\udc6e\u200d\u2642\ufe0f\u2b50","text":"<p><code>AssumptionSheriff</code> is a comprehensive Python package designed to validate statistical test assumptions. It provides automated checking of common statistical assumptions and offers recommendations when assumptions are violated. The packges supports 16 commonly used statistical tests, more tests will be added in the coming package updates.</p> <p>Unfortunately, it is quite common that published health research do not fully report or validate the underlying assumptions of statistical tests utilized as reported by many articles, see: </p> <ul> <li> <p>Hoekstra et al. (2012) \"Are Assumptions of Well-Known Statistical Techniques Checked, and Why (Not)?\" https://doi.org/10.3389/fpsyg.2012.00137</p> </li> <li> <p>Patino et. al (2018) \"Meeting the assumptions of statistical tests: an important and often forgotten step to reporting valid results\" https://doi.org/10.1590/S1806-37562018000000303</p> </li> <li> <p>Nielsen et. al (2019) \"Assessing assumptions for statistical analyses in randomised clinical trials\" https://doi.org/10.1136/bmjebm-2019-111174</p> </li> </ul> <p>To bridge this gap, <code>Assumption Sheriff</code>  automates the process of checking statistical test assumptions, providing clear feedback and suggestions for alternative approaches when violations occur.</p>"},{"location":"assumption_sheriff/#supported-statistical-tests","title":"Supported Statistical Tests","text":"<p><code>AssumptionSheriff</code> supports assumption checking for the following statistical tests:</p> <ol> <li>Independent Samples t-test <code>t_test_ind</code></li> <li>Repeated-Measures ANOVA <code>repeated_anova</code></li> <li>Logistic Regression <code>logistic</code></li> <li>Factorial ANOVA (Two-way ANOVA) <code>factorial_anova</code></li> <li>One-Way ANOVA (one_way_anova) <code>one_way_anova</code></li> <li>Pearson Correlation <code>pearson_correlation</code></li> <li>Paired t-test <code>paired_ttest</code></li> <li>Chi-Square Test of Independence <code>chi_square_independence</code></li> <li>Multiple Regression (<code>multiple_regression</code>)</li> <li>Two-Way ANOVA <code>two_way_anova</code></li> <li>Kaplan-Meier Analysis <code>kaplan_meier</code></li> <li>Cox Proportional Hazards <code>cox_ph</code></li> <li>Poisson Regression <code>poisson</code></li> <li>Spearman Correlation <code>spearman</code></li> <li>Wilcoxon Signed-Rank Test <code>wilcoxon_signed_rank</code></li> <li>MANOVA (Multivariate Analysis of Variance) <code>manova</code></li> </ol> <p>More tests to be added in future vesrions.</p>"},{"location":"assumption_sheriff/#key-features","title":"Key Features","text":"<ol> <li>Comprehensive assumption checking</li> <li>Recommendations for alternative methods</li> <li>Flexible integration</li> <li>Commonly used test support</li> </ol> <p>Citation</p> <p>If you use AssumptionSheriff in your research, please cite: <pre><code>@software{assumptionsheriff2024,\n    title = {AssumptionSheriff: A Python Package for Statistical Assumption Checking},\n    author = {Mohsen Askar},\n    e-mail = {ceaser198511@gmail.com},\n    year = {2024},\n    url = {https://pypi.org/project/assumption-sheriff/}\n}\n</code></pre></p>"},{"location":"assumption_sheriff/api/","title":"API Reference","text":""},{"location":"assumption_sheriff/api/#the-package-is-broadly-divided-into","title":"The package is broadly divided into:","text":""},{"location":"assumption_sheriff/api/#mixin-classes","title":"Mixin Classes:","text":"<p>To handle specific assumption checks:</p> <ul> <li><code>NormalityChecker</code> class: Checks normality using Shapiro-Wilk test, skewness, and kurtosis.</li> <li><code>HomoscedasticityChecker</code> class: Checks homoscedasticity using Levene's test.</li> <li><code>MonotonicityChecker</code> class: Checks monotonic relationships using Spearman correlation.</li> <li><code>PairedDataChecker</code> class: Checks if data is properly paired.</li> <li><code>CategoricalDataChecker</code> class: Checks if variables are categorical.</li> <li><code>MultivariateNormalityChecker</code> class: Checks multivariate normality using Mardia's test.</li> <li><code>SurvivalDataChecker</code> class: Checks basic requirements for survival data.</li> <li><code>ProportionalHazardsChecker</code> class: Checks proportional hazards using Schoenfeld residuals.</li> <li><code>PairedDifferenceChecker</code> class: Checks properties of paired differences.</li> </ul>"},{"location":"assumption_sheriff/api/#specific-checkers","title":"Specific Checkers:","text":"<p>Specific checkers for various statistical tests, each inheriting from AssumptionChecker and relevant mixins:</p> <ul> <li><code>IndependentTTestChecker</code> class: For Independent Samples t-test</li> <li><code>RepeatedMeasuresANOVAChecker</code> class: For Repeated ANOVA</li> <li><code>LogisticRegressionChecker</code> class: For Logistic Regression</li> <li><code>PearsonCorrelationChecker</code> class: For Pearson correlation</li> <li><code>PairedTTestChecker</code> class: For Paired t-test</li> <li><code>ChiSquareIndependenceChecker</code> class: For Chi-square independence test</li> <li><code>MultipleRegressionChecker</code> class: For Multiple Linear Regression</li> <li><code>TwoWayANOVAChecker</code> class: For Two-way ANOVA</li> <li><code>KaplanMeierChecker</code> class: For Kaplan-Meier</li> <li><code>CoxPHChecker</code> class: For </li> <li><code>PoissonRegressionChecker</code> class: For Cox Proportional Hazards </li> <li><code>SpearmanCorrelationChecker</code> class: For Spearman Corraletion</li> <li><code>WilcoxonSignedRankChecker</code> class: For Wilcoxon Signed-Rank Test</li> <li><code>MANOVAChecker</code> class: For MANOVA</li> <li><code>OneWayANOVAChecker</code> class: For One-way ANOVA</li> <li><code>FactorialANOVAChecker</code> class: For Factorial ANOVA</li> <li>Main Class: StatisticalTestAssumptions is the main class that manages the assumption checkers. It allows checking assumptions for a specified test type and provides recommendations based on the results.</li> </ul>"},{"location":"assumption_sheriff/api/#inlcuded-tests-assumptions","title":"Inlcuded tests assumptions","text":""},{"location":"assumption_sheriff/api/#independent-samples-t-test-t_test_ind","title":"Independent Samples t-test <code>t_test_ind</code>","text":"<ol> <li>Normality: The dependent variable should be (approximately) normally distributed within each group.</li> <li>Homogeneity of Variances: The population variances in the two groups should be equal (often checked using Levene\u2019s test).</li> <li>Independence of Observations: Each observation in one group is independent of any observation in the other group.</li> </ol>"},{"location":"assumption_sheriff/api/#repeated-measures-anova-repeated_anova","title":"Repeated-Measures ANOVA <code>repeated_anova</code>","text":"<ol> <li>Normality: The dependent variable should be (approximately) normally distributed at each time point or for each repeated measure.</li> <li>Sphericity: The variances of the differences between all possible pairs of repeated-measure conditions should be equal (often checked by Mauchly\u2019s test).</li> <li>Independence of Observations: Observations from different subjects are assumed to be independent, although repeated measures on the same subject are inherently correlated.</li> </ol>"},{"location":"assumption_sheriff/api/#logistic-regression-logistic","title":"Logistic Regression <code>logistic</code>","text":"<ol> <li>Dependent Variable: Binary (two categories, e.g., \u201csuccess/fail\u201d or \u201cdisease/no disease\u201d). Independence of Errors: Residuals (errors) should be independent across observations.</li> <li>Lack of Multicollinearity: Predictor variables should not be too highly correlated with each other.</li> <li>Linearity in the Logit: Although logistic regression is for categorical outcomes, continuous predictors should have a linear relationship with the log odds of the outcome.</li> </ol>"},{"location":"assumption_sheriff/api/#factorial-anova-factorial_anova","title":"Factorial ANOVA <code>factorial_anova</code>","text":"<ol> <li>Normality: The dependent variable in each cell of the design should be (approximately) normally distributed.</li> <li>Homogeneity of Variances: The variance across all cells (factorial combinations of levels) should be equal.</li> <li>Independence of Observations: Observations in each cell are independent of those in other cells and within cells.</li> </ol>"},{"location":"assumption_sheriff/api/#one-way-anova-one_way_anova","title":"One-Way ANOVA <code>one_way_anova</code>","text":"<ol> <li>Normality: The dependent variable should be (approximately) normally distributed in each group.</li> <li>Homogeneity of Variances: The variances in each of the groups are assumed to be equal.</li> <li>Independence of Observations: Observations in one group should be independent from those in other groups.</li> </ol>"},{"location":"assumption_sheriff/api/#pearson-correlation-pearson_correlation","title":"Pearson Correlation <code>pearson_correlation</code>","text":"<ol> <li>Linearity: The relationship between the two variables should be linear.</li> <li>Normality (for Significance Testing): Each variable should be (approximately) normally distributed if you want to use significance tests and confidence intervals for r.</li> <li>Interval or Ratio Scale: Both variables are typically continuous and measured on an interval or ratio scale.</li> <li>Independence of Observations: Each pair of observations comes from independent subjects or units.</li> </ol>"},{"location":"assumption_sheriff/api/#paired-t-test-paired_ttest","title":"Paired t-test <code>paired_ttest</code>","text":"<ol> <li>Normality of Difference Scores: The differences between the paired observations should be (approximately) normally distributed.</li> <li>Dependence of Observations: Each pair is taken from the same subject or matched subjects (hence, \u201cpaired\u201d).</li> <li>No Significant Outliers: Extreme outliers in the difference scores can affect the test.</li> </ol>"},{"location":"assumption_sheriff/api/#chi-square-test-of-independence-chi_square_independence","title":"Chi-Square Test of Independence <code>chi_square_independence</code>","text":"<ol> <li>Independence of Observations: Each subject or unit should be counted only once in the contingency table.</li> <li>Expected Cell Frequency: Each cell in the contingency table should have an expected count of at least 5 (rule of thumb for validity of p-values).</li> <li>Categorical Variables: Both variables should be categorical (nominal or ordinal).</li> </ol>"},{"location":"assumption_sheriff/api/#multiple-regression-multiple_regression","title":"Multiple Regression <code>multiple_regression</code>","text":"<ol> <li>Linearity: The relationship between each predictor and the outcome (dependent variable) is assumed to be linear in the parameters.</li> <li>Independence of Errors: Residuals should be independent (often checked by plotting residuals vs. predicted values).</li> <li>Homoscedasticity: The variance of residuals is constant across all levels of the predictors (also checked by residual plots).</li> <li>Normality of Residuals: The residuals should be (approximately) normally distributed (checked with Q-Q plots).</li> <li>Lack of Multicollinearity: Predictors should not be too highly correlated with each other.</li> </ol>"},{"location":"assumption_sheriff/api/#two-way-anova-two_way_anova","title":"Two-Way ANOVA <code>two_way_anova</code>","text":"<ol> <li>Normality: The dependent variable in each group (combination of two independent factors) should be (approximately) normally distributed.</li> <li>Homogeneity of Variances: The variances across all factor-level combinations should be equal (Levene\u2019s test is common).</li> <li>Independence of Observations: Observations in one factor-level combination are independent from other factor-level combinations and within each combination.</li> </ol>"},{"location":"assumption_sheriff/api/#kaplan-meier-analysis-kaplan_meier","title":"Kaplan-Meier Analysis <code>kaplan_meier</code>","text":"<ol> <li>Random Censoring: Assumes that censoring is non-informative (the reason an individual leaves the study or is censored is independent of their underlying risk).</li> <li>Independence of Survival Times: Each subject\u2019s survival time is independent of others.</li> <li>Time-to-Event Data: Typically used when the outcome is the time until an event (e.g., death, relapse).</li> </ol>"},{"location":"assumption_sheriff/api/#cox-proportional-hazards-model-cox_ph","title":"Cox Proportional Hazards Model <code>cox_ph</code>","text":"<ol> <li>Proportional Hazards: The hazard functions for different groups (or at different levels of a covariate) are proportional over time (i.e., hazard ratios remain constant over time).</li> <li>Random/Non-Informative Censoring: Similar to Kaplan-Meier, censoring should not be related to the outcome.</li> <li>Linearity (for Continuous Covariates): Often assumed that continuous covariates have a log-linear relationship with the hazard.</li> <li>Independence of Observations: Each subject\u2019s time-to-event is independent (unless modeling random effects or frailty for clustering).</li> </ol>"},{"location":"assumption_sheriff/api/#poisson-regression-poisson","title":"Poisson Regression <code>poisson</code>","text":"<ol> <li>Count Outcome Variable: The dependent variable is a count (e.g., number of doctor visits).</li> <li>Mean-Variance Relationship: The Poisson model assumes the mean and variance are equal. (If variance &gt; mean significantly, a Negative Binomial model might be preferred.)</li> <li>Independence of Observations: Each count is assumed to be independent of the others.</li> <li>Linearity in the Log Link: The log of the expected count is assumed to be a linear combination of predictors.</li> </ol>"},{"location":"assumption_sheriff/api/#spearman-correlation-spearman","title":"Spearman Correlation <code>spearman</code>","text":"<ol> <li>Monotonic Relationship: The relationship between the two variables should be monotonic (does not have to be linear).</li> <li>Ordinal or Interval/Ratio Data: Although often used for ordinal data, Spearman correlation can also handle interval/ratio data that fail Pearson\u2019s normality assumption.</li> <li>Independence of Observations: Each pair of observations is assumed independent.</li> </ol>"},{"location":"assumption_sheriff/api/#wilcoxon-signed-rank-test-wilcoxon_signed_rank","title":"Wilcoxon Signed-Rank Test <code>wilcoxon_signed_rank</code>","text":"<ol> <li>Paired or Matched Samples: The same subjects measured twice, or matched subjects.</li> <li>Ordinal or Continuous Data: Used when data are ordinal or not normally distributed, but we assume differences can be meaningfully ranked.</li> <li>Symmetry of Distribution of Differences (Ideal): While not as strict as the normality assumption, it is often assumed that the distribution of differences is symmetrical around the median.</li> </ol>"},{"location":"assumption_sheriff/api/#manova-multivariate-analysis-of-variance-manova","title":"MANOVA (Multivariate Analysis of Variance) <code>manova</code>","text":"<ol> <li>Multivariate Normality: The combination of dependent variables follows a multivariate normal distribution within each group.</li> <li>Homogeneity of Variance-Covariance Matrices: The variance-covariance matrices for the dependent variables are the same in each group (Box\u2019s M test).</li> <li>Independence of Observations: Observations across groups (and within groups) are independent.</li> <li>No Multicollinearity Among Dependent Variables: If the dependent variables are very highly correlated, MANOVA might not be the best approach.</li> </ol>"},{"location":"assumption_sheriff/api/#suggested-test-alternatives-explanation","title":"Suggested test alternatives explanation","text":""},{"location":"assumption_sheriff/api/#independent-t-test","title":"Independent T-Test:","text":"<ul> <li> <p>Suggested Alternatives: Mann-Whitney U test, Welch's t-test</p> </li> <li> <p>Explanation:</p> </li> <li> <p>Mann-Whitney U test is a non-parametric alternative that does not assume normality.</p> </li> <li> <p>Welch's t-test is used when the assumption of equal variances is violated.</p> </li> </ul>"},{"location":"assumption_sheriff/api/#repeated-measures-anova","title":"Repeated Measures ANOVA:","text":"<ul> <li> <p>Suggested Alternatives: Friedman test, Mixed-effects model</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Friedman test is a non-parametric alternative for repeated measures.</p> </li> <li> <p>Mixed-effects model can handle violations of sphericity and other complex data structures.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#logistic-regression","title":"Logistic Regression:","text":"<ul> <li> <p>Suggested Alternatives: Penalized regression (Ridge, Lasso), Decision trees</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Penalized regression methods like Ridge and Lasso can handle multicollinearity.</p> </li> <li> <p>Decision trees do not assume linearity or independence of errors.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#pearson-correlation","title":"Pearson Correlation:","text":"<ul> <li> <p>Suggested Alternatives: Spearman rank correlation, Kendall rank correlation, Robust correlation methods</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Spearman rank correlation and Kendall rank correlation are non-parametric and do not assume normality.</p> </li> <li> <p>Robust correlation methods can handle outliers.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#paired-t-test","title":"Paired T-Test:","text":"<ul> <li> <p>Suggested Alternatives: Wilcoxon signed-rank test, Sign test, Randomization test</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Wilcoxon signed-rank test is a non-parametric alternative for paired data.</p> </li> <li> <p>Sign test is another non-parametric alternative.</p> </li> <li> <p>Randomization test can be used when assumptions are severely violated.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#chi-square-test-of-independence","title":"Chi-Square Test of Independence:","text":"<ul> <li> <p>Suggested Alternatives: Fisher's exact test, G-test of independence, Freeman-Halton test, Log-linear analysis</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Fisher's exact test is used for small sample sizes.</p> </li> <li> <p>G-test is an alternative to the chi-square test.</p> </li> <li> <p>Freeman-Halton test extends Fisher's test to larger tables.</p> </li> <li> <p>Log-linear analysis is used for more complex categorical data.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#multiple-linear-regression","title":"Multiple Linear Regression:","text":"<ul> <li> <p>Suggested Alternatives: Ridge Regression, Lasso Regression, Robust Regression, Quantile Regression, Non-linear regression models</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Ridge and Lasso Regression address multicollinearity.</p> </li> <li> <p>Robust Regression handles outliers.</p> </li> <li> <p>Quantile Regression does not assume homoscedasticity.</p> </li> <li> <p>Non-linear regression models are used when linearity is violated.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#two-way-anova","title":"Two-Way ANOVA:","text":"<ul> <li> <p>Suggested Alternatives: Non-parametric factorial analysis, Robust two-way ANOVA, Aligned Rank Transform ANOVA, Separate non-parametric tests with correction, Mixed-effects model</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Non-parametric factorial analysis is used when assumptions are violated.</p> </li> <li> <p>Robust ANOVA methods handle violations of assumptions.</p> </li> <li> <p>Aligned Rank Transform ANOVA is a non-parametric alternative.</p> </li> <li> <p>Mixed-effects model can handle complex designs.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#kaplan-meier-survival-analysis","title":"Kaplan-Meier Survival Analysis:","text":"<ul> <li> <p>Suggested Alternatives: Cox Proportional Hazards model, Parametric survival models, Competing risks analysis, Time-varying coefficient models</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Cox Proportional Hazards model is more flexible.</p> </li> <li> <p>Parametric survival models assume specific distributions.</p> </li> <li> <p>Competing risks analysis is used when there are competing events.</p> </li> <li> <p>Time-varying coefficient models handle time-dependent covariates.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#cox-proportional-hazards-regression","title":"Cox Proportional Hazards Regression:","text":"<ul> <li> <p>Suggested Alternatives: Stratified Cox model, Time-varying coefficient Cox model, Parametric survival models, Additive hazards models</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Stratified Cox model handles non-proportional hazards.</p> </li> <li> <p>Time-varying coefficient models address time-dependent effects.</p> </li> <li> <p>Parametric survival models assume specific distributions.</p> </li> <li> <p>Additive hazards models are an alternative to proportional hazards.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#poisson-regression-continued","title":"Poisson Regression (continued):","text":"<ul> <li> <p>Suggested Alternatives: Negative Binomial Regression, Zero-inflated Poisson Regression, Zero-inflated Negative Binomial Regression, Quasi-Poisson Regression</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Negative Binomial Regression is suitable when there is overdispersion (variance greater than the mean) in count data.</p> </li> <li> <p>Zero-inflated Poisson Regression is used when there are more zeros in the data than expected under a standard Poisson model.</p> </li> <li> <p>Zero-inflated Negative Binomial Regression combines the handling of excess zeros and overdispersion.</p> </li> <li> <p>Quasi-Poisson Regression is another approach to handle overdispersion by adjusting the variance function.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#spearmans-rank-correlation","title":"Spearman's Rank Correlation:","text":"<ul> <li> <p>Suggested Alternatives: Kendall's tau, Kendall's tau-b (for ties), Pearson correlation (if relationship is linear), Distance correlation (for non-monotonic relationships)</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Kendall's tau is a non-parametric measure of correlation that is less sensitive to ties than Spearman's.</p> </li> <li> <p>Kendall's tau-b is specifically designed to handle ties in the data.</p> </li> <li> <p>Pearson correlation can be used if the relationship is linear and assumptions of normality are met.</p> </li> <li> <p>Distance correlation is a more general measure that can detect both linear and non-linear associations.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#wilcoxon-signed-rank-test","title":"Wilcoxon Signed-Rank Test:","text":"<ul> <li> <p>Suggested Alternatives: Sign test (for asymmetric differences), Paired t-test (if differences are normal), Permutation test, Bootstrap methods</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Sign test is a simpler non-parametric test that can be used if the differences are not symmetrically distributed.</p> </li> <li> <p>Paired t-test is appropriate if the differences are normally distributed.</p> </li> <li> <p>Permutation test is a non-parametric method that does not rely on distributional assumptions.</p> </li> </ul> <p>Bootstrap methods provide a flexible approach to estimate the sampling distribution of the test statistic.</p> </li> </ul>"},{"location":"assumption_sheriff/api/#manova-multivariate-analysis-of-variance","title":"MANOVA (Multivariate Analysis of Variance):","text":"<ul> <li> <p>Suggested Alternatives: Separate univariate ANOVAs with Bonferroni correction, Robust MANOVA, Permutation MANOVA, Non-parametric multivariate tests (e.g., NPMANOVA), Linear Discriminant Analysis</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Separate univariate ANOVAs with Bonferroni correction control for Type I error across multiple tests.</p> </li> <li> <p>Robust MANOVA methods handle violations of assumptions such as multivariate normality.</p> </li> <li> <p>Permutation MANOVA is a non-parametric alternative that does not assume normality.</p> </li> <li> <p>Non-parametric multivariate tests like NPMANOVA are used when assumptions are violated.</p> </li> <li> <p>Linear Discriminant Analysis can be used for classification purposes when MANOVA assumptions are not met.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#one-way-anova","title":"One-Way ANOVA:","text":"<ul> <li> <p>Suggested Alternatives: Kruskal-Wallis H-test, Welch's ANOVA, Brown-Forsythe test</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Kruskal-Wallis H-test is a non-parametric alternative that does not assume normality.</p> </li> <li> <p>Welch's ANOVA is used when the assumption of equal variances is violated.</p> </li> <li> <p>Brown-Forsythe test is another alternative for testing equality of means when variances are unequal.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/api/#factorial-anova","title":"Factorial ANOVA:","text":"<ul> <li> <p>Suggested Alternatives: Non-parametric factorial analysis, Mixed-effects model, Robust ANOVA</p> </li> <li> <p>Explanation:</p> <ul> <li> <p>Non-parametric factorial analysis is used when assumptions of normality and homoscedasticity are violated.</p> </li> <li> <p>Mixed-effects model can handle complex designs and violations of sphericity.</p> </li> </ul> </li> </ul>"},{"location":"assumption_sheriff/usage/","title":"Usage Guide","text":""},{"location":"assumption_sheriff/usage/#installation","title":"Installation","text":"<p>The package can be installed using <code>pip</code>. The dependdencies are <code>pandas</code>,<code>numpy</code>, <code>scipy</code>, <code>lifelines</code>, and <code>statsmodels</code>.</p> <pre><code>pip install assumption_sheriff\n</code></pre>"},{"location":"assumption_sheriff/usage/#quick-start","title":"Quick Start","text":"<pre><code># Basic import of everything\nimport assumption_sheriff as ash\n</code></pre> <pre><code># or direct import of specific components\nfrom assumption_sheriff import StatisticalTestAssumptions\n</code></pre>"},{"location":"assumption_sheriff/usage/#detailed-user-example","title":"Detailed user example","text":"<pre><code># Generate a sample data to test the package \nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(123)\nn = 100\n\n# 1. Independent groups for t-test / one-way ANOVA / two-way ANOVA (factor A/B)\ngroup_bin = np.random.choice([0, 1], size=n)  \nfactorA = np.random.choice(['A1','A2'], size=n)  \nfactorB = np.random.choice(['B1','B2'], size=n) \n\n# 2. Continuous variables (for t-tests, ANOVAs, correlations, regressions, etc.)\ncont_var1 = np.random.normal(loc=50, scale=10, size=n)   \ncont_var2 = np.random.normal(loc=0, scale=5, size=n)     \ncont_var3 = np.random.normal(loc=100, scale=20, size=n) \n\n# 3. Repeated-measures variables (for repeated-measures ANOVA)\nrm_time1 = np.random.normal(loc=5, scale=1, size=n)  \nrm_time2 = rm_time1 + np.random.normal(loc=0.5, scale=0.5, size=n)  \nrm_time3 = rm_time1 + np.random.normal(loc=1.0, scale=0.5, size=n)  \n\n# 4. Paired data (for paired t-tests or Wilcoxon signed-rank)\npaired_pre = np.random.normal(loc=10, scale=2, size=n)\npaired_post = paired_pre + np.random.normal(loc=-1, scale=1, size=n)\n\n# 5. Logistic outcome (binary) for logistic regression\nlogistic_outcome = np.random.binomial(n=1, p=0.4, size=n)\n\n# 6. Categorical variables (for Chi-Square)\ncat_var1 = np.random.choice(['Yes','No'], size=n)\ncat_var2 = np.random.choice(['High','Low'], size=n)\n\n# 7. Survival data (time-to-event + event indicator for KM/Cox)\ntime_to_event = np.random.exponential(scale=10, size=n)\nevent_occurred = np.random.binomial(n=1, p=0.7, size=n)\n\n# 8. Count data (for Poisson regression)\ncount_data = np.random.poisson(lam=2, size=n)\n\n# 9. Ordinal data (for Spearman correlation or ordinal logistic)\nordinal_data = np.random.choice(['Mild','Moderate','Severe'], size=n)\n\n# 10. Additional continuous variables for correlations / MANOVA\nmanova_var1 = np.random.normal(loc=30, scale=5, size=n)\nmanova_var2 = np.random.normal(loc=60, scale=10, size=n)\n\n# Assemble everything into a DataFrame\ndata = pd.DataFrame({\n    'group_bin': group_bin,\n    'factorA': factorA,\n    'factorB': factorB,\n    'cont_var1': cont_var1,\n    'cont_var2': cont_var2,\n    'cont_var3': cont_var3,\n    'rm_time1': rm_time1,\n    'rm_time2': rm_time2,\n    'rm_time3': rm_time3,\n    'paired_pre': paired_pre,\n    'paired_post': paired_post,\n    'logistic_outcome': logistic_outcome,\n    'cat_var1': cat_var1,\n    'cat_var2': cat_var2,\n    'time_to_event': time_to_event,\n    'event_occurred': event_occurred,\n    'count_data': count_data,\n    'ordinal_data': ordinal_data,\n    'manova_var1': manova_var1,\n    'manova_var2': manova_var2\n})\n\nprint(data.head(5))\n</code></pre> <pre><code>   group_bin factorA factorB  cont_var1  cont_var2   cont_var3  rm_time1  \\\n0          0      A2      B2  54.743473  -6.186766   96.147700  4.413384   \n1          1      A1      B2  44.360761   0.620279  108.982712  5.154290   \n2          0      A1      B1  40.026785  -8.002203   97.092729  3.852763   \n3          0      A2      B1  38.999569   3.769344  137.374529  6.520166   \n4          0      A2      B1  42.435628  -1.234079   89.625923  5.189043\n\n   rm_time2  rm_time3  paired_pre  paired_post  logistic_outcome cat_var1  \\\n0  5.256786  5.338739   10.545469     8.320940                 0       No   \n1  5.947174  7.147672   10.850672    10.859323                 0      Yes   \n2  4.585648  4.515028    9.538192     8.055827                 1       No   \n3  6.311219  7.372252   17.143158    17.222955                 0      Yes   \n4  5.909335  5.162844    9.207688     7.786610                 1       No\n\n  cat_var2  time_to_event  event_occurred  count_data ordinal_data  \\\n0      Low       0.491169               1           5       Severe   \n1      Low      21.322712               1           2       Severe   \n2      Low       6.101167               1           0       Severe   \n3      Low      17.788497               1           1     Moderate   \n4     High       3.188856               0           1         Mild\n\n   manova_var1  manova_var2  \n0    35.227235    49.717239  \n1    25.034866    52.544302  \n2    32.711234    56.899888  \n3    32.427786    48.581779  \n4    33.709235    69.263657\n</code></pre>"},{"location":"assumption_sheriff/usage/#t-tests","title":"T-tests","text":"<pre><code># for independent t-test\n# ---------------------\n# Initialize checker\nchecker = ash.StatisticalTestAssumptions()\n\n# Check assumptions for independent t-test\nresults = checker.check_assumptions(\n    data=data,\n    test_type='t_test_ind',\n    variables=['cont_var1', 'cont_var2'],\n    group_column='group_bin'\n)\n\n# Get recommendation\nrecommendation = checker.get_recommendation(results)\nprint(recommendation)\n</code></pre> <pre><code>\u2713 All assumptions are met. You can proceed with the Independent t-test.\n</code></pre> <pre><code># for paired t-test\n# ---------------------\nchecker = ash.StatisticalTestAssumptions()\nresults = checker.check_assumptions(\n    data=data,\n    test_type='paired_ttest',\n    variables=['paired_pre', 'paired_post']\n)\n# Get recommendations\nrecommendation = checker.get_recommendation(results)\nprint(recommendation)\n</code></pre> <pre><code>\u2713 All assumptions are met. You can proceed with the Paired t-test.\n</code></pre>"},{"location":"assumption_sheriff/usage/#anovas","title":"ANOVAs","text":"<pre><code># One-way ANOVA\n# -------------\nchecker = ash.StatisticalTestAssumptions()\nresults = checker.check_assumptions(\n    data=data,\n    test_type='one_way_anova',\n    variables=['cont_var1', 'cont_var2'],\n    group_column='group_bin'\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation)\n</code></pre> <pre><code>\u2713 All assumptions are met. You can proceed with the One-way ANOVA.\n</code></pre> <pre><code># Two-Way ANOVA\n# ----------------\nchecker = ash.StatisticalTestAssumptions()\nresults = checker.check_assumptions(\n    data=data,\n    test_type='two_way_anova',\n    variables=['cont_var1'],\n    #dependent_var='cont_var1',\n    factors=['factorA', 'factorA']\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation) \n</code></pre> <pre><code>\u2713 All assumptions are met. You can proceed with the Two-way ANOVA.\n</code></pre> <pre><code># Factorial (Two-way) ANOVA\n# -----------------------\nchecker = ash.StatisticalTestAssumptions()\n# Sample data structure\ndata2 = pd.DataFrame({\n    'fertilizer': ['A', 'A', 'B', 'B'] * 25,\n    'watering': ['daily', 'weekly'] * 50,\n    'yield': np.random.normal(loc=[50, 45, 60, 55] * 25, scale=5)\n})\n\nresults = checker.check_assumptions(\n    data=data2,\n    test_type='factorial_anova',\n    variables=['yield'],\n    group_columns= ['fertilizer', 'watering']\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation)\n</code></pre> <pre><code>\u26a0 Some assumptions for Factorial ANOVA are violated:\n\n- Insufficient sample size in some cells (minimum 25 &lt; required 30)\n\nConsider these alternatives:\n- Non-parametric factorial analysis\n- Mixed-effects model\n- Robust ANOVA\n</code></pre> <pre><code># Repeated measures ANOVA\n#-------------------------\nchecker = ash.StatisticalTestAssumptions()\n# Check assumptions\nresults = checker.check_assumptions(\n    data=data,\n    test_type='repeated_anova',\n    variables=['rm_time1', 'rm_time2', 'rm_time3'],\n    subject_column='group_bin'\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation)\n</code></pre> <pre><code>\u2713 All assumptions are met. You can proceed with the Repeated Measures ANOVA.\n</code></pre> <pre><code># for MANOVA (Multivariate Analysis of Variance)\n#---------------------------------------------------\n\nchecker = ash.StatisticalTestAssumptions()\nresults = checker.check_assumptions(\n    data=data,\n    test_type='manova',\n    variables=['manova_var1', 'manova_var2'],\n    group_col='group_bin'\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation)\n</code></pre> <pre><code>\u26a0 Some assumptions for MANOVA are violated:\n\n- Multivariate normality violated in group_1\n- Number of dependent variables should ideally be greater than number of groups\n\nConsider these alternatives:\n- Separate univariate ANOVAs with Bonferroni correction\n- Robust MANOVA\n- Permutation MANOVA\n- Non-parametric multivariate tests (e.g., NPMANOVA)\n- Linear Discriminant Analysis\n</code></pre>"},{"location":"assumption_sheriff/usage/#correlation-tests","title":"Correlation tests","text":"<pre><code># for Pearson corraltion \n# --------------------------\nchecker = ash.StatisticalTestAssumptions()\nresults = checker.check_assumptions(\n    data=data,\n    test_type='pearson_correlation',\n    variables=['cont_var1', 'cont_var2']\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation)\n</code></pre> <pre><code>\u26a0 Some assumptions for Pearson Correlation are violated:\n\n- Variable pair cont_var1_vs_cont_var2 may not have a monotonic relationship (Spearman correlation=0.07)\n\nConsider these alternatives:\n- Spearman rank correlation\n- Kendall rank correlation\n- Robust correlation methods\n</code></pre> <pre><code># for spearman correlation\n#----------------------------\n\nchecker = ash.StatisticalTestAssumptions()\nresults = checker.check_assumptions(\n    data=data,\n    test_type='spearman',\n    variables=['ordinal_data', 'cont_var2']\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation) \n</code></pre> <pre><code>\u2713 All assumptions are met. You can proceed with the Spearman's Rank Correlation.\n</code></pre>"},{"location":"assumption_sheriff/usage/#chi-square-independence","title":"Chi-square independence","text":"<pre><code># for Chi-square test \n# ---------------------\nchecker = ash.StatisticalTestAssumptions()\nresults = checker.check_assumptions(\n    data=data,\n    test_type='chi_square_independence',\n    variables=['cat_var1', 'cat_var1']\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation)\n</code></pre> <pre><code>\u2713 All assumptions are met. You can proceed with the Chi-square test of independence.\n</code></pre>"},{"location":"assumption_sheriff/usage/#regression","title":"Regression","text":"<pre><code># For Logistic Regression\n#------------------------\nchecker = ash.StatisticalTestAssumptions()\n# Check assumptions\nresults = checker.check_assumptions(\n    data=data,\n    test_type='logistic',\n    variables=['cont_var1', 'cont_var2', 'cont_var3'],\n    dependent_var='logistic_outcome'\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation)\n</code></pre> <pre><code>\u26a0 Some assumptions for Logistic Regression are violated:\n\n- High multicollinearity detected for 'const' (VIF=58.70)\n\nConsider these alternatives:\n- Penalized regression (Ridge, Lasso)\n- Decision trees\n</code></pre> <pre><code># Multiple Linear Regression \n# ----------------------------\nchecker = StatisticalTestAssumptions()\nresults = checker.check_assumptions(\n    data=data,\n    test_type='multiple_regression',\n    variables=['cont_var1', 'cont_var2', 'cont_var3'],\n    dependent_var='logistic_outcome'\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation)\n</code></pre> <pre><code>\u26a0 Some assumptions for Multiple Linear Regression are violated:\n\n- Residuals are not normally distributed (Shapiro-Wilk p=0.0000)\n- Non-linear relationship detected for predictor 'cont_var1'\n- Non-linear relationship detected for predictor 'cont_var2'\n- High multicollinearity detected for variables: ['const']\n</code></pre> <pre><code># for Poisson regression \n#-----------------------------------------\nchecker = ash.StatisticalTestAssumptions()\nresults = checker.check_assumptions(\n    data=data,\n    test_type='poisson',\n    variables=[\n        'count_data',    # dependent variable must be first\n        'cont_var1',     # predictors follow\n        'cont_var2'\n    ],\n    offset_var='exposure_time'  # Optional\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation)\n</code></pre> <pre><code>\u26a0 Some assumptions for Poisson Regression are violated:\n\n- High multicollinearity detected for variables: ['const']\n\nConsider these alternatives:\n- Negative Binomial Regression\n- Zero-inflated Poisson Regression\n- Zero-inflated Negative Binomial Regression\n- Quasi-Poisson Regression\n</code></pre>"},{"location":"assumption_sheriff/usage/#survival-analysis","title":"Survival analysis","text":"<pre><code># for Kaplan-Meier \n# ----------------\nchecker = ash.StatisticalTestAssumptions()\nresults = checker.check_assumptions(\n    data=data,\n    test_type='kaplan_meier',\n    variables=['time_to_event', 'event_occurred'],  # time variable first, event variable second\n    group_col='group_bin'  # optional grouping variable\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation) \n</code></pre> <pre><code>\u2713 All assumptions are met. You can proceed with the Kaplan-Meier survival analysis.\n</code></pre> <pre><code># for Cox Proportional Hazards \n# -----------------------------\nchecker = ash.StatisticalTestAssumptions()\n\ncox_results = checker.check_assumptions(\n    data=data,\n    test_type='cox_ph',\n    variables=['time_to_event', 'event_occurred'],  # time variable first, event variable second\n    group_col='group_bin' \n) \n\nrecommendation = checker.get_recommendation(cox_results)\nprint(recommendation) \n</code></pre> <pre><code>\u2713 All assumptions are met. You can proceed with the Cox Proportional Hazards Regression.\n</code></pre>"},{"location":"assumption_sheriff/usage/#non-parametric-tests","title":"Non-parametric tests","text":"<pre><code># for Wilcoxon Signed-Rank Test\n#-------------------------------\nchecker = ash.StatisticalTestAssumptions()\nresults = checker.check_assumptions(\n    data=data,\n    test_type='wilcoxon_signed_rank',\n    variables=['paired_pre', 'paired_post']\n)\n\nrecommendation = checker.get_recommendation(results)\nprint(recommendation)\n</code></pre> <pre><code>\u2713 All assumptions are met. You can proceed with the Wilcoxon Signed-Rank Test.\n</code></pre>"},{"location":"assumption_sheriff/usage/#common-issues-and-solutions","title":"Common issues and solutions","text":""},{"location":"assumption_sheriff/usage/#1-handling-missing-data","title":"1. Handling missing data","text":"<p><code>AssumptionSheriff</code> automatically handles missing data in most cases. However, for best results: - Remove or impute missing values before checking assumptions - Ensure complete cases for paired tests - Document any data preprocessing steps</p>"},{"location":"assumption_sheriff/usage/#2-dealing-with-outliers","title":"2. Dealing with outliers","text":"<p>When outliers are detected: - Review them for data entry errors - Consider robust statistical methods - Document justification for outlier handling</p>"},{"location":"assumption_sheriff/usage/#3-small-sample-sizes","title":"3. Small sample sizes","text":"<p>For small samples: - Consider non-parametric alternatives - Use exact tests when available - Be cautious with assumption violations</p>"},{"location":"audio2topics/","title":"Overview","text":""},{"location":"audio2topics/#audio2topics-package","title":"<code>Audio2Topics</code> Package \ud83d\udd0a\ud83d\uddc2\ufe0f","text":"<p><code>Audio2Topics</code> is python packge that automizes topic extraction from voice files. The package is originally designed to aid researchers that performs interview research. Interview research typically incorporates a series of steps, starting from planning research questions, performing interviews, transcribing, and thorough manual text analysis to extract the main themes and topics of the transcribed text. This manual analysis phase is usually long and time-consuming. Additionally, the feasibility of manual analysis is limited by the volume of transcribed data.  <code>Audio2Topics</code> accelerating this step by automtically converting voice files of interviews into topics simply and effectively.</p> <p>The application provides an end-to-end pipeline that handles: - Audio transcription using OpenAI's Whisper - Text preprocessing and cleaning - Topic modeling with multiple algorithms - Topic validation and optimization - Advanced visualizations - Model comparison and evaluation</p> <p>Audio2Topics bridges the gap between audio content and text analysis, making topic discovery accessible to researchers, content creators, analysts, and anyone who needs to identify key themes in audio materials.</p>"},{"location":"audio2topics/#key-features","title":"Key Features","text":"<ul> <li>Automated Audio Transcription: Convert audio files to text using state-of-the-art speech recognition</li> <li>Advanced Text Processing: Clean and normalize text with customizable preprocessing options</li> <li>Multiple Topic Modeling Approaches: Choose from BERTopic, LDA, and NMF algorithms</li> <li>Interactive Topic Exploration: Visualize and explore topics through multiple visualization techniques</li> <li>Topic Quality Validation: Assess topic coherence, diversity, and coverage</li> <li>Topic Highlighting: See how topics appear in original text with color highlighting</li> <li>Model Comparison: Compare different topic modeling approaches side by side</li> <li>LLM Integration: Enhance topic interpretability with AI-generated descriptions</li> <li>Comprehensive Reporting: Generate detailed reports with findings and visualizations</li> </ul>"},{"location":"audio2topics/#workflow-overview","title":"Workflow Overview","text":"<p>The Audio2Topics application guides users through a structured workflow:</p> <ol> <li>Audio Transcription \u2192 2. Text Processing \u2192 3. Topic Modeling \u2192 4. Validation &amp; Visualization</li> </ol>"},{"location":"audio2topics/#1-audio-transcription","title":"1. Audio Transcription","text":"<p>The first step involves converting audio files to text using OpenAI's Whisper model: - Upload audio files (MP3, WAV, M4A, FLAC) - Select Whisper model size (tiny to large) - Transcribe with automatic language detection - Review and save transcriptions</p>"},{"location":"audio2topics/#2-text-processing","title":"2. Text Processing","text":"<p>The transcribed text is then prepared for topic modeling: - Clean text by removing stopwords, special characters, etc. - Apply stemming or lemmatization - Process multiple documents simultaneously - Analyze text statistics for quality assessment</p>"},{"location":"audio2topics/#3-topic-modeling","title":"3. Topic Modeling","text":"<p>The core functionality extracts topics from processed text: - Choose from multiple algorithms (BERTopic, NMF, LDA) - Configure parameters like number of topics and n-gram range - Extract topics with adaptive processing for challenging data - Refine topics with LLM-generated descriptions</p>"},{"location":"audio2topics/#4-validation-visualization","title":"4. Validation &amp; Visualization","text":"<p>Finally, assess topic quality and explore results: - Validate topics with coherence and diversity metrics - Find the optimal number of topics for your data - Create visualizations from word clouds to interactive topic maps - Highlight topics in original text - Compare different topic modeling approaches - Generate reports for sharing and documentation</p>"},{"location":"audio2topics/#module-summary","title":"Module Summary","text":"<p>Audio2Topics consists of several specialized modules, each handling a different aspect of the audio-to-topics pipeline:</p>"},{"location":"audio2topics/#audio-transcription-module","title":"Audio Transcription Module","text":"<p>The transcription module converts audio files to text using OpenAI's Whisper speech recognition technology. - Key Components: Transcriber class, TranscriberWorker, TranscriberTab - Features: Multiple model sizes, GPU acceleration, language detection, batch processing - Detailed Transcriber Documentation</p>"},{"location":"audio2topics/#text-processing-module","title":"Text Processing Module","text":"<p>The text processor prepares raw text for topic modeling through cleaning, normalization, and standardization. - Key Components: TextProcessor class, TextProcessorWorker, ProcessorTab - Features: Stopword removal, lemmatization, n-gram extraction, text statistics - Detailed Text Processor Documentation</p>"},{"location":"audio2topics/#topic-modeling-module","title":"Topic Modeling Module","text":"<p>The topic modeler extracts meaningful topics from processed text using multiple algorithms and approaches. - Key Components: TopicModeler class, TopicModelingWorker, TopicTab - Features: BERTopic, NMF, and LDA algorithms, adaptive processing, LLM topic refinement - Detailed Topic Modeler Documentation</p>"},{"location":"audio2topics/#validation-module","title":"Validation Module","text":"<p>The validator assesses topic quality and helps find the optimal topic model configuration. - Key Components: TopicValidator class, ValidationWorker, OptimizationWorker, ValidatorTab - Features: Coherence metrics, diversity assessment, topic count optimization - Detailed Validator Documentation</p>"},{"location":"audio2topics/#visualization-module","title":"Visualization Module","text":"<p>The visualizer creates static and interactive visualizations of text and topic data. - Key Components: Visualizer class, VisualizationWorker, VisualizerTab - Features: Word clouds, topic heatmaps, interactive visualizations, topic highlighting - Detailed Visualizer Documentation</p>"},{"location":"audio2topics/#comparison-module","title":"Comparison Module","text":"<p>The comparison tool enables side-by-side evaluation of different topic modeling approaches. - Key Components: ComparisonTab class, TopicModelRun, ComparisonRunDialog - Features: Multiple model runs, comparison visualizations, parameter impact analysis - Detailed Comparison Documentation</p>"},{"location":"audio2topics/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"audio2topics/#system-requirements","title":"System Requirements","text":"<ul> <li>Python 3.8 or higher</li> <li>4GB RAM minimum (8GB+ recommended for larger models)</li> <li>NVIDIA GPU with CUDA support (optional, for faster processing)</li> <li>Internet connection for model downloads and API access</li> </ul>"},{"location":"audio2topics/#dependencies","title":"Dependencies","text":"<p>Audio2Topics relies on several key libraries: - PyQt5 for the user interface - OpenAI Whisper for speech recognition - NLTK and spaCy for text processing - BERTopic, scikit-learn, and UMAP for topic modeling - Matplotlib, seaborn, and wordcloud for visualizations - OpenAI/Anthropic APIs for LLM integration (optional)</p>"},{"location":"audio2topics/#installation-steps","title":"Installation Steps","text":"<p>Install the package <pre><code>pip install audio2topics\n</code></pre></p> <p>Configure API Keys (Optional)    - For LLM topic refinement, configure OpenAI or Anthropic API keys in the settings</p> <p>Launch the application    - In the terminal, activate the enviroments where the packages is installed and type:</p> <p><pre><code>audio2topics\n</code></pre> Or    <pre><code>python -m audio2topics\n</code></pre></p>"},{"location":"audio2topics/#use-cases","title":"Use Cases","text":"<p>Audio2Topics serves a wide range of applications across different domains:</p>"},{"location":"audio2topics/#academic-research","title":"Academic Research","text":"<ul> <li>Analyze interview recordings for qualitative research</li> <li>Process lecture content to identify key themes</li> <li>Extract topics from academic presentations and symposia</li> </ul>"},{"location":"audio2topics/#business-intelligence","title":"Business Intelligence","text":"<ul> <li>Discover trends in customer support calls</li> <li>Analyze meeting recordings for key discussion points</li> <li>Process earnings calls and investor presentations</li> </ul>"},{"location":"audio2topics/#media-analysis","title":"Media Analysis","text":"<ul> <li>Extract topics from podcast episodes</li> <li>Analyze broadcast interviews and discussions</li> <li>Identify themes in documentary content</li> </ul>"},{"location":"audio2topics/#personal-knowledge-management","title":"Personal Knowledge Management","text":"<ul> <li>Process recorded notes and ideas</li> <li>Analyze personal audio journals</li> <li>Extract topics from recorded lectures or webinars</li> </ul>"},{"location":"audio2topics/#troubleshooting","title":"Troubleshooting","text":""},{"location":"audio2topics/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"audio2topics/#audio-transcription","title":"Audio Transcription","text":"<ul> <li>Issue: Transcription fails to start</li> <li>Solution: Check internet connection, try a smaller model size, ensure sufficient disk space</li> </ul>"},{"location":"audio2topics/#text-processing","title":"Text Processing","text":"<ul> <li>Issue: Many stopwords in processed text</li> <li>Solution: Adjust language setting, add custom stopwords, check preprocessing settings</li> </ul>"},{"location":"audio2topics/#topic-modeling","title":"Topic Modeling","text":"<ul> <li>Issue: \"Dimensionality error\" with BERTopic</li> <li>Solution: Enable adaptive processing, try BERTopic-PCA or NMF instead</li> </ul>"},{"location":"audio2topics/#validation","title":"Validation","text":"<ul> <li>Issue: Low coherence scores</li> <li>Solution: Try different preprocessing, adjust number of topics, try another algorithm</li> </ul>"},{"location":"audio2topics/#visualization","title":"Visualization","text":"<ul> <li>Issue: Interactive visualization not loading</li> <li>Solution: Check if the model type matches the visualization type, try a different visualization</li> </ul>"},{"location":"audio2topics/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Use smaller Whisper models (base/small) for faster transcription</li> <li>Process documents in smaller batches for memory efficiency</li> <li>Use GPU acceleration when available</li> <li>Save models and results for reuse</li> </ul>"},{"location":"audio2topics/#best-practices","title":"Best Practices","text":""},{"location":"audio2topics/#audio-recording-quality","title":"Audio Recording Quality","text":"<ul> <li>Use clear recordings with minimal background noise</li> <li>Ensure adequate volume levels</li> <li>Use lossless formats when possible</li> </ul>"},{"location":"audio2topics/#document-preparation","title":"Document Preparation","text":"<ul> <li>Split long recordings into shorter segments</li> <li>Group related content into meaningful documents</li> <li>Remove irrelevant sections before processing</li> </ul>"},{"location":"audio2topics/#topic-modeling-strategy","title":"Topic Modeling Strategy","text":"<ol> <li>Start with a small subset of documents to test different approaches</li> <li>Use the Comparison tab to identify the best method for your data</li> <li>Validate topic quality before drawing conclusions</li> <li>Use LLM refinement for clearer topic interpretations</li> <li>Combine quantitative metrics with human judgment</li> </ol>"},{"location":"audio2topics/#reporting-and-sharing","title":"Reporting and Sharing","text":"<ul> <li>Export visualizations in appropriate formats for your audience</li> <li>Include topic words and example documents in reports</li> <li>Provide context for topics through LLM-generated descriptions</li> <li>Use interactive formats (HTML) for detailed exploration</li> </ul>"},{"location":"audio2topics/#glossary","title":"Glossary","text":"<ul> <li>BERTopic: Topic modeling algorithm that leverages BERT embeddings</li> <li>Coherence: Measure of how semantically related the words within a topic are</li> <li>Diversity: Measure of how distinct topics are from each other</li> <li>Elbow Method: Technique for finding the optimal number of topics</li> <li>LDA: Latent Dirichlet Allocation, a probabilistic topic modeling method</li> <li>Lemmatization: Process of reducing words to their base or dictionary form</li> <li>N-gram: Contiguous sequence of n items from a text sample</li> <li>NMF: Non-negative Matrix Factorization, a topic modeling algorithm</li> <li>Stopwords: Common words that are filtered out during text processing</li> <li>UMAP: Uniform Manifold Approximation and Projection, a dimensionality reduction technique</li> <li>Whisper: OpenAI's speech recognition model for audio transcription</li> </ul>"},{"location":"audio2topics/#references-and-resources","title":"References and Resources","text":""},{"location":"audio2topics/#underlying-technologies","title":"Underlying Technologies","text":"<ul> <li>OpenAI Whisper</li> <li>BERTopic</li> <li>spaCy</li> <li>scikit-learn</li> <li>PyQt</li> </ul>"},{"location":"audio2topics/#license","title":"License","text":"<p>Released under the MIT License: For more details, see the <code>LICENSE</code> file. Copyright (C) 2024 <code>stata_codebook</code></p> <p>Developed by: Mohsen Askar ceaser198511@gmail.com</p> <p>Citation</p> <p>If you use Stata Codebook in your research, please cite: <pre><code>@software{stata_codebook2024,\n    title = {AssumptionSheriff: A Python Package for Statistical Assumption Checking},\n    author = {Mohsen Askar},\n    e-mail = {ceaser198511@gmail.com},\n    year = {2024},\n    url = {https://pypi.org/project/stata_codebook/}\n}\n</code></pre></p>"},{"location":"audio2topics/compare_models/","title":"Topic Model Comparison Module","text":""},{"location":"audio2topics/compare_models/#overview","title":"Overview","text":"<p>The Topic Model Comparison module enables you to run and evaluate multiple topic modeling approaches side by side, helping identify the optimal method and parameters for your specific data. This experimental approach takes the guesswork out of topic modeling by quantitatively measuring how different algorithms and settings perform on the same dataset.</p> <p>This module allows you to: - Configure and run multiple topic modeling methods with different parameters - Visualize similarities and differences between topic models - Compare topic coherence, distinctiveness, and distribution - Analyze how parameter changes affect topic quality - Generate detailed reports with findings and recommendations - Export comparison results for documentation and sharing</p> <p>By systematically comparing approaches, you can make data-driven decisions about which topic modeling method will best reveal the underlying themes in your documents.</p> <p>Main interface of the Comparison Tab </p>"},{"location":"audio2topics/compare_models/#core-components","title":"Core Components","text":""},{"location":"audio2topics/compare_models/#comparisontab-class","title":"ComparisonTab Class","text":"<p>The <code>ComparisonTab</code> class is the main UI component that manages the comparison process, visualizations, and reporting.</p>"},{"location":"audio2topics/compare_models/#key-methods","title":"Key Methods","text":"Method Description <code>start_comparison()</code> Launches the comparison configuration dialog and initiates the process <code>execute_runs()</code> Manages the execution of multiple topic model runs in sequence <code>generate_visualizations()</code> Creates all comparison visualizations when runs are complete <code>generate_summary_report()</code> Creates a detailed analysis of the comparison with recommendations <code>export_report()</code> Exports the comparison results in HTML or Markdown format"},{"location":"audio2topics/compare_models/#topicmodelrun-class","title":"TopicModelRun Class","text":"<p>The <code>TopicModelRun</code> class stores all information about a single topic modeling run, including its configuration, results, and metrics.</p>"},{"location":"audio2topics/compare_models/#properties","title":"Properties","text":"Property Description <code>name</code> User-defined name for the run <code>method</code> Topic modeling method used (BERTopic, NMF, LDA, etc.) <code>parameters</code> Configuration parameters used for the run <code>documents</code> Documents processed in this run <code>topics</code> Topic assignments for each document <code>topic_words</code> Words and their weights for each topic <code>metrics</code> Quality metrics calculated for this run <code>timestamp</code> When the run was executed"},{"location":"audio2topics/compare_models/#helper-dialogs","title":"Helper Dialogs","text":"<ul> <li>RunConfigDialog: UI for configuring a single topic model run</li> <li>ComparisonRunDialog: UI for setting up multiple runs to compare</li> <li>ElbowMethodDialog: Interactive tool for finding optimal LDA topic counts</li> </ul>"},{"location":"audio2topics/compare_models/#user-interface","title":"User Interface","text":"<p>The Comparison Tab provides a comprehensive interface for setting up, visualizing, and analyzing multiple topic model runs.</p>"},{"location":"audio2topics/compare_models/#ui-components","title":"UI Components","text":"<ul> <li>Control Buttons:</li> <li>\"Start New Comparison\" button to configure and run a new comparison</li> <li> <p>\"Export Report\" button to export comparison results</p> </li> <li> <p>Run Selection Table:</p> </li> <li>Displays all completed runs with their methods, parameters, and metrics</li> <li> <p>Allows selection of specific runs for detailed comparison</p> </li> <li> <p>Visualization Tabs:</p> </li> <li>Topic Similarity: Heatmap showing relationship between topics across runs</li> <li>Word Weights: Comparison of word importance in similar topics</li> <li>Topic Distribution: Chart showing document distribution across topics</li> <li>Parameter Impact: Analysis of how parameters affect topic quality</li> <li>Summary Report: Detailed analysis with findings and recommendations</li> </ul>"},{"location":"audio2topics/compare_models/#usage-guide","title":"Usage Guide","text":""},{"location":"audio2topics/compare_models/#starting-a-comparison","title":"Starting a Comparison","text":"<ol> <li>Ensure you have documents loaded in the application</li> <li>Click the \"Start New Comparison\" button</li> <li>In the dialog that appears, click \"Add Run\" to configure your first run</li> <li>For each run:</li> <li>Provide a descriptive name</li> <li>Select a topic modeling method</li> <li>Configure parameters (number of topics, min topic size, etc.)</li> <li>Click OK to add the run to the comparison</li> <li>Add 2-5 runs with different methods or parameters</li> <li>Click \"Start Comparison\" to begin processing</li> </ol>"},{"location":"audio2topics/compare_models/#run-configuration-options","title":"Run Configuration Options","text":"<p>When configuring each run, you can adjust these key parameters:</p> <ul> <li>Method: </li> <li>BERTopic (UMAP): High-quality semantic topics using BERT embeddings</li> <li>BERTopic (PCA): More stable BERTopic variant using PCA</li> <li>NMF: Non-negative Matrix Factorization for traditional topic modeling</li> <li> <p>LDA: Latent Dirichlet Allocation, a probabilistic approach</p> </li> <li> <p>Language: Select the primary language of your documents</p> </li> <li>Number of Topics: Set a specific number or choose \"Auto\"</li> <li>Min Topic Size: Minimum documents required to form a topic</li> <li>N-gram Range: Whether to include phrases (2+ words) in topics</li> </ul> <p>For LDA models, additional options are available: - Elbow Method: Automatically find the optimal number of topics - Min/Max Topics: Range to search for the optimal topic count - Step Size: Granularity of the topic count search</p>"},{"location":"audio2topics/compare_models/#understanding-visualizations","title":"Understanding Visualizations","text":""},{"location":"audio2topics/compare_models/#topic-similarity-heatmap","title":"Topic Similarity Heatmap","text":"<p>This visualization shows how topics from different runs relate to each other: - Each cell represents similarity between two topics (from same or different runs) - Darker colors indicate higher similarity - Helps identify consistent topics that appear across multiple methods - Shows which topics are method-specific versus universal in your data</p>"},{"location":"audio2topics/compare_models/#word-weights-comparison","title":"Word Weights Comparison","text":"<p>Compares word importance between similar topics across different runs: - Select a topic to see how its top words compare to similar topics in other runs - Bar height shows word importance (weight) in each topic - Helps evaluate topic coherence and specificity across methods - Reveals semantic differences in how methods interpret similar concepts</p>"},{"location":"audio2topics/compare_models/#topic-distribution-chart","title":"Topic Distribution Chart","text":"<p>Shows how documents are distributed across topics in different runs: - Compares distribution balance between methods - Identifies methods that produce more evenly distributed topics - Shows if some methods create \"catch-all\" topics or many small topics - Helps evaluate coverage and granularity of different approaches</p>"},{"location":"audio2topics/compare_models/#parameter-impact-chart","title":"Parameter Impact Chart","text":"<p>Visualizes how changing parameters affects topic quality: - Scatter plot showing relationship between number of topics and topic quality - Points colored by method to compare different approaches - Helps identify optimal parameter settings for your data - Reveals how methods scale with different parameter values</p>"},{"location":"audio2topics/compare_models/#interpreting-the-summary-report","title":"Interpreting the Summary Report","text":"<p>The Summary Report provides a comprehensive analysis of your comparison, including:</p> <ol> <li>Run Summary: Overview of all runs with their key metrics</li> <li>Top Topic Words: The most important words for each topic across all runs</li> <li>Recommendations: Data-driven suggestions for optimal methods and parameters</li> <li>Method Analysis: Comparative strengths and weaknesses of different approaches</li> <li>Parameter Recommendations: Guidance on ideal parameter values for your data</li> </ol>"},{"location":"audio2topics/compare_models/#recommendations-methodology","title":"Recommendations Methodology","text":"<p>The report uses several metrics to identify the best approach:</p> <ul> <li>Optimal Number of Topics: Based on the average number of meaningful topics found across all runs</li> <li>Best Method: Typically the run with highest topic coherence and balanced distribution</li> <li>N-gram Setting: Based on which n-gram range produces most distinctive topics</li> <li>Topic Size Threshold: Determined by analyzing distribution balance</li> </ul>"},{"location":"audio2topics/compare_models/#exporting-comparison-results","title":"Exporting Comparison Results","text":"<ol> <li>Click the \"Export Report\" button</li> <li>Choose a format:</li> <li>HTML: Rich formatting with tables and styling, ideal for sharing</li> <li>Markdown: Plain text with formatting, good for documentation</li> <li>Select a save location and filename</li> <li>The exported report contains:</li> <li>All run configurations and their results</li> <li>Top words for each topic across all runs</li> <li>Analysis and recommendations</li> <li>Summary metrics and charts</li> </ol>"},{"location":"audio2topics/compare_models/#best-practices","title":"Best Practices","text":""},{"location":"audio2topics/compare_models/#effective-comparison-strategy","title":"Effective Comparison Strategy","text":"<ol> <li>Vary one parameter at a time to isolate its impact</li> <li>Include diverse methods to get different perspectives on your data</li> <li>Use descriptive run names to easily identify them in visualizations</li> <li>Test a range of topic numbers to find the optimal granularity</li> <li>Compare results with domain knowledge to validate topic quality</li> </ol>"},{"location":"audio2topics/compare_models/#when-to-use-each-method","title":"When to Use Each Method","text":"<ul> <li>BERTopic (UMAP): Best for semantic understanding, works well with medium-sized datasets</li> <li>BERTopic (PCA): Good alternative when UMAP is unstable with small datasets</li> <li>NMF: Fast, deterministic results; good for clearly distinct topics</li> <li>LDA: Works well with longer documents; provides probabilistic topic assignments</li> </ul>"},{"location":"audio2topics/compare_models/#identifying-the-best-model","title":"Identifying the Best Model","text":"<p>The \"best\" topic model depends on your specific goals:</p> <ul> <li>For exploration: Prioritize coherence and interpretability</li> <li>For document organization: Look for balanced distribution and clear separation</li> <li>For content analysis: Focus on specific, meaningful topics</li> <li>For classification: Emphasize predictive power and coverage</li> </ul>"},{"location":"audio2topics/compare_models/#common-pitfalls-to-avoid","title":"Common Pitfalls to Avoid","text":"<ol> <li>Relying on a single metric: Consider multiple aspects of topic quality</li> <li>Overlooking preprocessing impact: Document cleaning affects all models</li> <li>Assuming more topics means better results: Quality often peaks at a moderate number</li> <li>Neglecting outlier topics: Check how many documents lack clear topic assignments</li> <li>Focusing only on top words: Consider full topic coherence and document assignments</li> </ol>"},{"location":"audio2topics/compare_models/#advanced-usage","title":"Advanced Usage","text":""},{"location":"audio2topics/compare_models/#customizing-the-comparison-process","title":"Customizing the Comparison Process","text":"<ul> <li>Run a focused sub-comparison on the most promising methods</li> <li>Try different preprocessing approaches to see their impact on topic quality</li> <li>Combine insights from multiple models for more robust topic identification</li> <li>Compare stability by running the same configuration on different document subsets</li> </ul>"},{"location":"audio2topics/compare_models/#handling-special-cases","title":"Handling Special Cases","text":""},{"location":"audio2topics/compare_models/#very-small-document-sets","title":"Very Small Document Sets","text":"<ul> <li>Focus on NMF and LDA which are more stable with few documents</li> <li>Use topic_size=1 to allow single-document topics</li> <li>Consider document chunking to increase document count</li> </ul>"},{"location":"audio2topics/compare_models/#multi-language-corpora","title":"Multi-Language Corpora","text":"<ul> <li>Use \"multilingual\" setting for mixed-language document sets</li> <li>Compare language-specific versus multilingual models</li> <li>Check topic distribution to ensure fair representation across languages</li> </ul>"},{"location":"audio2topics/compare_models/#domain-specific-content","title":"Domain-Specific Content","text":"<ul> <li>Pay special attention to technical terminology in topic words</li> <li>Adjust min_df and max_df in NMF/LDA to handle specialized vocabulary</li> <li>Compare with domain expert assessment for topic quality validation</li> </ul>"},{"location":"audio2topics/text_processor/","title":"Text Processing Module","text":""},{"location":"audio2topics/text_processor/#overview","title":"Overview","text":"<p>The Text Processing module prepares raw text for topic modeling by cleaning, normalizing, and standardizing content. This critical step transforms unstructured text into a suitable format for analysis, helping to produce more coherent and meaningful topic clusters.</p> <p>This module allows you to: - Process text from multiple sources (direct input, text files, CSV files, and Word documents) - Clean text by removing stopwords, special characters, and irrelevant elements - Apply advanced NLP techniques including tokenization, lemmatization, and stemming - Generate detailed text statistics to understand document characteristics - Process documents in multiple languages (currently English and Norwegian)</p> <p>Main interface of the Text Processor Tab</p> <p></p>"},{"location":"audio2topics/text_processor/#core-components","title":"Core Components","text":""},{"location":"audio2topics/text_processor/#textprocessor-class","title":"TextProcessor Class","text":"<p>The <code>TextProcessor</code> class serves as the main interface for text processing functionality. It manages the processing workflow and provides methods for calculating text statistics and handling language selection.</p>"},{"location":"audio2topics/text_processor/#methods","title":"Methods","text":"Method Description Parameters Returns <code>process_text()</code> Starts processing documents using a worker thread <code>documents</code>: String or list of strings to process<code>language</code>: Language for text processing Returns the worker thread that can be connected to signals <code>get_available_languages()</code> Gets list of supported languages None List of supported languages <code>get_text_statistics()</code> Calculates text statistics synchronously <code>text</code>: Text to analyze<code>language</code>: Language for text processing List of tuples with statistic name and value"},{"location":"audio2topics/text_processor/#textprocessorworker-class","title":"TextProcessorWorker Class","text":"<p>The <code>TextProcessorWorker</code> class extends <code>QThread</code> to handle text processing in a background thread, keeping the UI responsive during processing.</p>"},{"location":"audio2topics/text_processor/#signals","title":"Signals","text":"Signal Description Parameters <code>progress_updated</code> Emitted to update progress <code>int</code>: progress percentage, <code>str</code>: status message <code>processing_completed</code> Emitted when processing is done <code>list</code>: list of processed documents <code>error_occurred</code> Emitted when an error occurs <code>str</code>: error message"},{"location":"audio2topics/text_processor/#key-text-processing-functions","title":"Key Text Processing Functions","text":"Function Description Parameters <code>clean_text()</code> Cleans text by removing stopwords, special characters, and applying stemming/lemmatization <code>text</code>: Text to clean<code>language</code>: Language for processing<code>nlp</code>: Pre-loaded SpaCy model (optional) <code>calculate_text_statistics()</code> Calculates various text statistics <code>text</code>: Text to analyze<code>language</code>: Language for processing <code>load_spacy_model()</code> Loads SpaCy model with caching and thread safety <code>language</code>: Language for the model"},{"location":"audio2topics/text_processor/#text-processing-steps","title":"Text Processing Steps","text":"<p>The text processor performs several operations to prepare text for topic modeling:</p> <ol> <li>Email and URL Removal: Identifies and removes email addresses and web URLs</li> <li>Special Character Removal: Strips punctuation, symbols, and other non-alphanumeric characters</li> <li>Number Removal: Eliminates numeric digits that typically don't contribute to topic meaning</li> <li>Case Normalization: Converts all text to lowercase for consistent processing</li> <li>Tokenization: Breaks text into individual words or tokens</li> <li>Stopword Removal: Filters out common words (like \"the\", \"and\", \"is\") that don't contribute to meaning</li> <li>Stemming (optional): Reduces words to their root form by removing prefixes and suffixes</li> <li>Lemmatization: Reduces words to their dictionary base form to group similar words together</li> </ol>"},{"location":"audio2topics/text_processor/#user-interface","title":"User Interface","text":"<p>The ProcessorTab class provides the user interface for text processing functionality.</p>"},{"location":"audio2topics/text_processor/#ui-components","title":"UI Components","text":"<ul> <li>Text Input Panel:</li> <li>Text area for entering or loading text</li> <li> <p>Document loading from text files, CSV files, and Word documents</p> </li> <li> <p>Processing Controls:</p> </li> <li>Language selection dropdown</li> <li>Process button</li> <li>Load and Clear buttons</li> <li> <p>Progress bar with status updates</p> </li> <li> <p>Output Display:</p> </li> <li>Processed text view</li> <li> <p>Text statistics table</p> </li> <li> <p>CSV Import Dialog:</p> </li> <li>Options for CSV delimiter, encoding, and header detection</li> <li>Column selection for multi-column CSV files</li> <li>Data preview table</li> </ul>"},{"location":"audio2topics/text_processor/#usage-guide","title":"Usage Guide","text":""},{"location":"audio2topics/text_processor/#entering-text","title":"Entering Text","text":"<p>Text can be added to the processor in multiple ways:</p> <ol> <li>Direct Input: Type or paste text directly into the text area</li> <li>Loading Files: Click \"Load Text Files\" to open supported file types:</li> <li>Text files (*.txt)</li> <li>CSV files (*.csv) with column selection</li> <li>Word documents (*.docx)</li> </ol>"},{"location":"audio2topics/text_processor/#processing-options","title":"Processing Options","text":"<ol> <li>Language Selection: Choose the appropriate language from the dropdown</li> <li>Currently supported: English and Norwegian</li> <li> <p>Language selection affects stopword removal, stemming, and lemmatization</p> </li> <li> <p>Processing: Click \"Process Text\" to begin cleaning the text</p> </li> <li>The progress bar shows status updates during processing</li> <li>Results appear in the \"Processed Text\" tab when complete</li> </ol>"},{"location":"audio2topics/text_processor/#working-with-csv-files","title":"Working with CSV Files","text":"<p>When importing CSV files, a dialog appears allowing you to:</p> <ol> <li>Configure import options:</li> <li>Select delimiter (comma, semicolon, tab, pipe, or custom)</li> <li>Choose file encoding (UTF-8, ASCII, ISO-8859-1, etc.)</li> <li> <p>Specify whether the first row contains headers</p> </li> <li> <p>Select columns to import:</p> </li> <li>Choose specific columns to include in the text</li> <li>Preview the data before importing</li> </ol> <p>This is particularly useful for importing structured data where only certain columns contain relevant text for topic modeling.</p>"},{"location":"audio2topics/text_processor/#understanding-text-statistics","title":"Understanding Text Statistics","text":"<p>After processing, the Statistics tab displays various metrics about your text:</p> Statistic Description Number of sentences Total count of sentences detected in the text Number of tokens Total count of words and other elements before filtering Number of unique words Count of distinct words, showing vocabulary richness Number of words (excluding stopwords) Count of meaningful words after removing common stopwords Number of stop words Count of common words that were filtered out Average sentence length Average number of words per sentence Most common words List of the most frequently occurring words and their counts Number of characters Total character count in the text Average word length Average number of characters per word <p>These statistics help evaluate text characteristics and verify the effects of processing.</p>"},{"location":"audio2topics/text_processor/#language-support","title":"Language Support","text":"<p>The text processor supports multiple languages with language-specific processing:</p>"},{"location":"audio2topics/text_processor/#currently-supported-languages","title":"Currently Supported Languages","text":"<ul> <li>English: Complete support for stopwords, stemming, and lemmatization using NLTK and SpaCy's <code>en_core_web_sm</code> model</li> <li>Norwegian: Full language support including Nordic-specific processing using SpaCy's <code>nb_core_news_sm</code> model</li> </ul> <p>Each language has specific: - Stopword lists for filtering common words - Stemming algorithms tailored to language structure - Lemmatization dictionaries for word normalization</p>"},{"location":"audio2topics/text_processor/#language-specific-considerations","title":"Language-Specific Considerations","text":"<ul> <li>Select the predominant language for documents with mixed language content</li> <li>Processing effectiveness varies by language, with best results for the fully supported languages</li> <li>The system uses SpaCy's language models, which are loaded dynamically the first time they're needed</li> </ul>"},{"location":"audio2topics/text_processor/#tips-for-effective-text-processing","title":"Tips for Effective Text Processing","text":""},{"location":"audio2topics/text_processor/#best-practices","title":"Best Practices","text":"<ol> <li>Check Before and After: Review both original and processed text to ensure important content isn't lost</li> <li>Balance Cleaning Aggressiveness: </li> <li>Too aggressive: Important terms may be removed</li> <li>Too lenient: Noise may affect topic modeling quality</li> <li>Use Consistent Processing: Apply the same settings to related documents</li> <li>Provide Adequate Volume: Aim for at least several thousand words total across all documents</li> <li>Structure Your Documents: Each document should ideally cover a coherent topic or subtopic</li> </ol>"},{"location":"audio2topics/text_processor/#domain-specific-considerations","title":"Domain-Specific Considerations","text":"<ul> <li>Technical Content: Consider preserving specialized terminology even if uncommon</li> <li>Names and Entities: Proper nouns may be important despite being uncommon words</li> <li>Abbreviations: Standardize abbreviations and acronyms where possible</li> <li>Multilingual Content: Process documents in their primary language for best results</li> </ul>"},{"location":"audio2topics/text_processor/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"Issue Solution Over-processing removes important terms Review processed text and adjust settings if needed Under-processing leaves too much noise Check statistics for high counts of unique words that may indicate insufficient cleaning Very short documents Combine related short texts into more substantial documents Mixed languages in documents Split by language or process using the predominant language Special domain vocabulary removed Consider creating a custom stopword list that preserves domain terms"},{"location":"audio2topics/text_processor/#troubleshooting","title":"Troubleshooting","text":""},{"location":"audio2topics/text_processor/#csv-import-issues","title":"CSV Import Issues","text":"<ul> <li>CSV parsing errors: Try different delimiter settings or check for file corruption</li> <li>Character encoding problems: Select a different encoding (UTF-8, ISO-8859-1, etc.)</li> <li>Large CSV files: For very large files (&gt;10MB), consider splitting or pre-filtering the data</li> </ul>"},{"location":"audio2topics/text_processor/#processing-performance","title":"Processing Performance","text":"<ul> <li>Slow processing: </li> <li>SpaCy models are loaded the first time they're used, causing initial delay</li> <li>Processing speed depends on document size and complexity</li> <li>Large documents with many sentences take longer to process</li> </ul>"},{"location":"audio2topics/text_processor/#language-support-limitations","title":"Language Support Limitations","text":"<ul> <li>Unsupported languages: Currently limited to English and Norwegian</li> <li>Stemming unavailable: If no stemmer is available for a language, the system will skip stemming</li> <li>Missing stopwords: If no stopwords are available, an empty set is used</li> </ul>"},{"location":"audio2topics/topic_modeler/","title":"Topic Modeling Module","text":""},{"location":"audio2topics/topic_modeler/#overview","title":"Overview","text":"<p>The Topic Modeling module is the heart of the Audio2Topics application, enabling automatic discovery of thematic patterns in text. It extracts meaningful topics from processed documents, making it possible to understand the main themes in your audio content without having to read through every transcript.</p> <p>This module provides: - Multiple topic modeling approaches (BERTopic, NMF, LDA) - Adaptive processing for small document collections - Topic visualization and exploration tools - LLM-powered topic refinement - Advanced options for customizing the topic extraction process</p> <p>Main interface of the Topic Modeling Tab </p>"},{"location":"audio2topics/topic_modeler/#core-components","title":"Core Components","text":""},{"location":"audio2topics/topic_modeler/#topicmodeler-class","title":"TopicModeler Class","text":"<p>The <code>TopicModeler</code> class is the main interface for topic modeling functionality. It manages the extraction process and provides methods for handling topic models.</p>"},{"location":"audio2topics/topic_modeler/#methods","title":"Methods","text":"Method Description Parameters Returns <code>extract_topics()</code> Starts topic modeling on documents using a worker thread <code>documents</code>: List of document strings<code>language</code>: Language for topic modeling<code>n_gram_range</code>: Tuple of min and max n-gram sizes<code>min_topic_size</code>: Minimum topic size<code>nr_topics</code>: Number of topics to extract...(other parameters) Returns the worker thread that can be connected to signals <code>transform_documents()</code> Transforms new documents using an existing model <code>documents</code>: List of document strings Tuple of (topics, probabilities) <code>get_topic_info()</code> Gets information about the topics in the model None Dictionary with topic information <code>get_topics()</code> Gets the topics and their words from the model None Dictionary mapping topic IDs to lists of (word, score) tuples <code>save_model()</code> Saves the topic model to disk <code>path</code>: Path to save the model None <code>load_model()</code> Loads a topic model from disk <code>path</code>: Path to the saved model None"},{"location":"audio2topics/topic_modeler/#topicmodelingworker-class","title":"TopicModelingWorker Class","text":"<p>The <code>TopicModelingWorker</code> extends <code>QThread</code> to handle topic modeling in a background thread, keeping the UI responsive during processing.</p>"},{"location":"audio2topics/topic_modeler/#signals","title":"Signals","text":"Signal Description Parameters <code>progress_updated</code> Emitted to update progress <code>int</code>: progress percentage, <code>str</code>: status message <code>topics_extracted</code> Emitted when topics are extracted <code>topics</code>: list of topic assignments<code>probs</code>: list of topic probabilities<code>topics_words</code>: dictionary of topic words<code>topic_info</code>: topic information<code>model</code>: the trained model <code>error_occurred</code> Emitted when an error occurs <code>str</code>: error message <code>show_elbow_dialog</code> Emitted to show the elbow method dialog <code>list</code>: model scores, <code>list</code>: topics range"},{"location":"audio2topics/topic_modeler/#topic-modeling-approaches","title":"Topic Modeling Approaches","text":"<p>The module supports multiple topic modeling methods, each with different strengths:</p>"},{"location":"audio2topics/topic_modeler/#1-bertopic-with-umap","title":"1. BERTopic with UMAP","text":"<p>This is the primary method and provides the highest quality results for most use cases.</p> <ul> <li>Strengths: </li> <li>Semantic understanding of text through BERT embeddings</li> <li>High-quality, coherent topics</li> <li>Works well with multiple languages</li> <li> <p>Captures nuanced themes in text</p> </li> <li> <p>Limitations:</p> </li> <li>Can fail with very small document sets (less than ~20 documents)</li> <li>More computationally intensive than traditional methods</li> </ul>"},{"location":"audio2topics/topic_modeler/#2-bertopic-with-pca","title":"2. BERTopic with PCA","text":"<p>A more stable variant of BERTopic that works better with smaller document sets.</p> <ul> <li>Strengths:</li> <li>More robust with small document collections</li> <li>Still leverages BERT's semantic understanding</li> <li> <p>Better stability than UMAP-based approach</p> </li> <li> <p>Limitations:</p> </li> <li>Topics may be slightly less coherent than with UMAP</li> <li>Still requires a minimum number of documents</li> </ul>"},{"location":"audio2topics/topic_modeler/#3-nmf-non-negative-matrix-factorization","title":"3. NMF (Non-negative Matrix Factorization)","text":"<p>A traditional matrix factorization approach that works well with smaller document sets.</p> <ul> <li>Strengths:</li> <li>Very stable even with very few documents</li> <li>Deterministic results (same input always gives same output)</li> <li> <p>Computationally efficient</p> </li> <li> <p>Limitations:</p> </li> <li>Less semantic understanding than BERTopic</li> <li>Based solely on word co-occurrence patterns</li> <li>Typically less coherent topics</li> </ul>"},{"location":"audio2topics/topic_modeler/#4-lda-latent-dirichlet-allocation","title":"4. LDA (Latent Dirichlet Allocation)","text":"<p>The classic probabilistic topic modeling algorithm, now enhanced with an elbow method for optimal topic selection.</p> <ul> <li>Strengths:</li> <li>Well-established probabilistic model</li> <li>Works well with larger documents</li> <li>Explicit topic distributions for each document</li> <li> <p>Includes elbow method for automatically finding optimal number of topics</p> </li> <li> <p>Limitations:</p> </li> <li>Performs poorly with very short texts</li> <li>Less semantic coherence than BERTopic</li> <li>May require more tuning</li> </ul>"},{"location":"audio2topics/topic_modeler/#user-interface","title":"User Interface","text":"<p>The TopicTab class provides a comprehensive interface for configuring, running, and exploring topic models.</p>"},{"location":"audio2topics/topic_modeler/#ui-components","title":"UI Components","text":"<ul> <li>Topic Model Settings:</li> <li>Method selection (BERTopic UMAP, BERTopic PCA, NMF, LDA)</li> <li>Language selection</li> <li>Number of topics control</li> <li>Minimum topic size</li> <li> <p>N-gram range</p> </li> <li> <p>LDA-specific Options:</p> </li> <li>Elbow method controls for finding optimal topic count</li> <li> <p>Min/max topics range and step size</p> </li> <li> <p>Adaptive Processing Settings:</p> </li> <li>Toggle for enabling/disabling adaptive processing</li> <li> <p>Max retries and chunk size settings</p> </li> <li> <p>Topic Exploration:</p> </li> <li>Topic overview table with keywords and descriptions</li> <li>Document-topic assignment view</li> <li> <p>Detailed keyword exploration for each topic</p> </li> <li> <p>LLM Refinement:</p> </li> <li>Integration with OpenAI and Anthropic models</li> <li>Topic description generation</li> <li>Interactive refinement dialog</li> </ul>"},{"location":"audio2topics/topic_modeler/#dialogs","title":"Dialogs","text":"<ul> <li>ElbowMethodDialog: Interactive tool for finding the optimal number of topics when using LDA</li> <li>RefineTopicsDialog: Interface for enhancing topic interpretability with LLM-generated descriptions</li> </ul>"},{"location":"audio2topics/topic_modeler/#usage-guide","title":"Usage Guide","text":""},{"location":"audio2topics/topic_modeler/#configuring-topic-modeling","title":"Configuring Topic Modeling","text":"<ol> <li>Select a Topic Modeling Method:</li> <li>BERTopic (UMAP): Best quality but may fail with small document sets</li> <li>BERTopic (PCA): Good quality, more stable with small document sets</li> <li>NMF: Traditional method, very stable but less semantic coherence</li> <li> <p>LDA: Classic topic modeling, works well with larger document sets</p> </li> <li> <p>Choose Basic Parameters:</p> </li> <li>Language: Select the primary language of your documents</li> <li>Number of Topics: Set to \"Auto\" or choose a specific number</li> <li>Min Topic Size: Minimum number of documents required to form a topic</li> <li> <p>N-gram Range: Controls whether phrases (2+ words) can be in topics</p> </li> <li> <p>Set Method-Specific Options:</p> </li> <li>For LDA, you can enable the elbow method to automatically find the optimal number of topics</li> <li> <p>Configure the min/max topics range and step size for elbow analysis</p> </li> <li> <p>Configure Adaptive Processing (for handling challenging document sets):</p> </li> <li>Enable adaptive processing to automatically adjust parameters if errors occur</li> <li>Set max retries and chunk size for document splitting</li> </ol>"},{"location":"audio2topics/topic_modeler/#extracting-topics","title":"Extracting Topics","text":"<ol> <li>Click \"Extract Topics\" to begin the process</li> <li>The progress bar shows status updates during extraction</li> <li>If using LDA with elbow method, an interactive dialog will appear to help select the optimal number of topics</li> <li>When complete, the extracted topics will be displayed in the Topics view</li> </ol>"},{"location":"audio2topics/topic_modeler/#understanding-the-results","title":"Understanding the Results","text":"<p>The results are presented in three tabs:</p> <ol> <li>Topic Overview:</li> <li>Shows each topic's ID, document count, representative words, and description</li> <li> <p>Provides a high-level view of all topics in your collection</p> </li> <li> <p>Document Topics:</p> </li> <li>Lists each document with its assigned topic and probability</li> <li> <p>Shows how documents are distributed across topics</p> </li> <li> <p>Topic Keywords:</p> </li> <li>Displays detailed keywords for a selected topic</li> <li>Shows the importance score for each word</li> </ol>"},{"location":"audio2topics/topic_modeler/#refining-topics-with-llm","title":"Refining Topics with LLM","text":"<ol> <li>Click \"Refine Topics with LLM\" to improve topic interpretability</li> <li>Select the LLM provider (OpenAI or Anthropic)</li> <li>Choose which topics to refine</li> <li>Click \"Refine Topics\" to generate human-readable descriptions</li> <li>Review the results and click \"OK\" to apply the descriptions</li> </ol>"},{"location":"audio2topics/topic_modeler/#adaptive-processing","title":"Adaptive Processing","text":"<p>The adaptive processing feature helps overcome common challenges in topic modeling, particularly with small document collections or single large documents.</p>"},{"location":"audio2topics/topic_modeler/#how-it-works","title":"How It Works","text":"<p>When enabled, adaptive processing will:</p> <ol> <li>Document Chunking: If you have very few documents (especially just one), it will automatically split them into smaller chunks to create a sufficient number of documents for topic modeling</li> <li>Method Fallbacks: If the primary method fails, it will try alternative approaches in this order:</li> <li>BERTopic with UMAP</li> <li>BERTopic with PCA</li> <li>NMF or LDA</li> <li>Parameter Adjustments: It will automatically adjust key parameters like n_neighbors and n_components in UMAP to better match your document collection</li> </ol>"},{"location":"audio2topics/topic_modeler/#when-to-use-it","title":"When to Use It","text":"<ul> <li>When processing a single large document</li> <li>When working with very few documents (less than 10-20)</li> <li>When experiencing dimensionality errors with UMAP</li> <li>When standard parameters fail to produce results</li> </ul>"},{"location":"audio2topics/topic_modeler/#configuration","title":"Configuration","text":"<ul> <li>Max Retries: How many parameter combinations to try before giving up</li> <li>Initial Chunk Size: Word count for document splitting (if needed)</li> </ul>"},{"location":"audio2topics/topic_modeler/#lda-elbow-method","title":"LDA Elbow Method","text":"<p>Finding the optimal number of topics is critical for meaningful results. The LDA Elbow method provides an objective approach to this problem.</p>"},{"location":"audio2topics/topic_modeler/#how-it-works_1","title":"How It Works","text":"<ol> <li>The system trains multiple LDA models with different numbers of topics</li> <li>Each model is evaluated for quality using log-likelihood and topic distinctiveness</li> <li>The results are plotted as a quality curve</li> <li>The \"elbow point\" in this curve indicates the optimal number of topics - the point where adding more topics yields diminishing returns</li> <li>You can accept the recommended number or choose your own</li> </ol>"},{"location":"audio2topics/topic_modeler/#using-the-elbow-method","title":"Using the Elbow Method","text":"<ol> <li>Select \"LDA\" as your topic modeling method</li> <li>Enable \"Use elbow method to find optimal number of topics\"</li> <li>Configure the range (min/max topics) and step size</li> <li>Run topic extraction</li> <li>When the dialog appears, review the curve and select the desired number of topics</li> </ol>"},{"location":"audio2topics/topic_modeler/#tips-and-best-practices","title":"Tips and Best Practices","text":""},{"location":"audio2topics/topic_modeler/#getting-better-results","title":"Getting Better Results","text":"<ol> <li>Document Preparation:</li> <li>Ensure documents are properly cleaned and processed</li> <li>Try to have at least 10-20 documents for meaningful topics</li> <li> <p>Documents should be substantial (at least several sentences)</p> </li> <li> <p>Method Selection:</p> </li> <li>Start with BERTopic (UMAP) for best quality</li> <li>Switch to BERTopic (PCA) if UMAP fails or you have fewer documents</li> <li>Use NMF for very small document sets</li> <li> <p>Try LDA for traditional probabilistic topic modeling</p> </li> <li> <p>Parameter Tuning:</p> </li> <li>Adjust the number of topics based on the size and diversity of your collection</li> <li>Increase min_topic_size for fewer, broader topics</li> <li>Decrease min_topic_size for more specific topics</li> <li> <p>Use bigrams (n_gram_range=(1,2)) to capture meaningful phrases</p> </li> <li> <p>Topic Interpretation:</p> </li> <li>Use the LLM refinement feature to get human-readable descriptions</li> <li>Look at the document-topic assignments to understand what documents contribute to each topic</li> <li>Check topic keywords to understand the essence of each topic</li> </ol>"},{"location":"audio2topics/topic_modeler/#troubleshooting","title":"Troubleshooting","text":"Issue Solution \"Dimensionality error\" with BERTopic Enable adaptive processing or switch to BERTopic (PCA) Too many documents in Topic -1 (outlier topic) Decrease min_topic_size or try a different topic modeling method Topics don't make sense Try a different method or adjust the number of topics Processing fails with very few documents Enable adaptive processing to automatically chunk documents Want more interpretable topics Use the \"Refine Topics with LLM\" feature"},{"location":"audio2topics/topic_modeler/#technical-details","title":"Technical Details","text":""},{"location":"audio2topics/topic_modeler/#topic-representation","title":"Topic Representation","text":"<p>Topics are represented by:</p> <ol> <li>Topic IDs: Numeric identifiers for each topic (Topic -1 is the outlier topic)</li> <li>Keywords: Important words for each topic with relevance scores</li> <li>Document Assignments: Which documents belong to each topic</li> <li>Probabilities: How strongly each document relates to its assigned topic</li> </ol>"},{"location":"audio2topics/topic_modeler/#output-data-structures","title":"Output Data Structures","text":"<ul> <li>topics: List of topic IDs assigned to each document</li> <li>probs: List of topic probability distributions for each document</li> <li>topics_words: Dictionary mapping topic IDs to lists of (word, score) tuples</li> <li>topic_info: Dictionary with metadata about each topic, including counts and names</li> </ul>"},{"location":"audio2topics/topic_modeler/#model-persistence","title":"Model Persistence","text":"<p>You can save and load topic models for later use:</p>"},{"location":"audio2topics/topic_modeler/#llm-integration","title":"LLM Integration","text":"<p>The module integrates with OpenAI and Anthropic models to:</p> <ol> <li>Generate human-readable topic descriptions</li> <li>Improve topic interpretability</li> <li>Provide context that might not be evident from keywords alone</li> </ol> <p>This feature requires valid API keys to be configured in the settings.</p>"},{"location":"audio2topics/transcriber/","title":"Audio Transcription Module","text":""},{"location":"audio2topics/transcriber/#overview","title":"Overview","text":"<p>The Audio Transcription module enables users to convert audio files to text using OpenAI's Whisper speech recognition technology. It forms the first step in the Audio2Topics workflow, providing accurate transcriptions of audio content for further text processing and topic modeling.</p> <p>This module allows you to: - Load multiple audio files in various formats (MP3, WAV, M4A, FLAC) - Select from different Whisper model sizes based on your accuracy and speed requirements - Process files using either CPU or GPU acceleration - View and save transcriptions to text files</p> <p>Main interface of the Transcriber Tab </p>"},{"location":"audio2topics/transcriber/#core-components","title":"Core Components","text":""},{"location":"audio2topics/transcriber/#transcriber-class","title":"Transcriber Class","text":"<p>The <code>Transcriber</code> class serves as the main interface for audio transcription functionality. It manages the transcription process and provides methods for saving results and querying available resources.</p>"},{"location":"audio2topics/transcriber/#methods","title":"Methods","text":"Method Description Parameters Returns <code>transcribe_files()</code> Starts transcribing audio files using a worker thread <code>audio_files</code>: Dict[str, bytes] - Dictionary mapping filenames to file content<code>model_name</code>: str - Whisper model name to use Returns the worker thread that can be connected to signals <code>save_transcriptions()</code> Saves transcriptions to text files <code>transcriptions</code>: Dict[str, str] - Dictionary with filenames as keys and transcriptions as values<code>output_dir</code>: str - Directory to save files List[str] - List of paths to saved transcription files <code>get_available_devices()</code> Gets list of available devices for transcription None List[str] - List of available devices (CPU and GPUs if available) <code>get_available_models()</code> Gets list of available Whisper models None List[str] - List of available model names"},{"location":"audio2topics/transcriber/#transcriberworker-class","title":"TranscriberWorker Class","text":"<p>The <code>TranscriberWorker</code> class extends <code>QThread</code> to handle audio transcription in a background thread, keeping the UI responsive during processing.</p>"},{"location":"audio2topics/transcriber/#signals","title":"Signals","text":"Signal Description Parameters <code>progress_updated</code> Emitted to update progress <code>int</code>: progress percentage, <code>str</code>: status message <code>transcription_completed</code> Emitted when transcription is done <code>dict</code>: dictionary of transcriptions <code>error_occurred</code> Emitted when an error occurs <code>str</code>: error message"},{"location":"audio2topics/transcriber/#user-interface","title":"User Interface","text":"<p>The TranscriberTab class provides the user interface for the audio transcription functionality.</p>"},{"location":"audio2topics/transcriber/#ui-components","title":"UI Components","text":"<ul> <li>Audio Files Panel:</li> <li>File list showing loaded audio files</li> <li> <p>Load and Clear buttons for file management</p> </li> <li> <p>Transcription Controls:</p> </li> <li>Model selection dropdown (tiny, base, small, medium, large)</li> <li>Device selection (CPU/GPU options)</li> <li>Language auto-detection toggle</li> <li>Transcribe button</li> <li> <p>Progress bar</p> </li> <li> <p>Transcription View:</p> </li> <li>Text area showing the current transcription</li> <li>Save button for exporting transcriptions</li> </ul>"},{"location":"audio2topics/transcriber/#usage-guide","title":"Usage Guide","text":""},{"location":"audio2topics/transcriber/#loading-audio-files","title":"Loading Audio Files","text":"<ol> <li>Click the \"Load Audio Files\" button to open the file selection dialog</li> <li>Select one or more audio files (supported formats: MP3, WAV, M4A, FLAC)</li> <li>Selected files will appear in the file list on the left panel</li> </ol>"},{"location":"audio2topics/transcriber/#selecting-transcription-options","title":"Selecting Transcription Options","text":"<ol> <li>Choose a Whisper model from the dropdown:</li> <li>tiny: Fastest, lowest accuracy (~75MB)</li> <li>base: Fast with improved accuracy (~142MB)</li> <li>small: Good balance of speed and accuracy (~466MB)</li> <li>medium: High quality for most use cases (~1.5GB)</li> <li> <p>large: Maximum accuracy for challenging audio (~3GB)</p> </li> <li> <p>Select a device:</p> </li> <li>CPU: Available on all systems</li> <li> <p>CUDA: Available if you have an NVIDIA GPU with CUDA support</p> </li> <li> <p>Optionally toggle language auto-detection (enabled by default)</p> </li> </ol>"},{"location":"audio2topics/transcriber/#starting-transcription","title":"Starting Transcription","text":"<ol> <li>Click the \"Transcribe\" button to begin processing</li> <li>The progress bar will display the current status</li> <li>Transcription speed depends on:</li> <li>Model size</li> <li>Audio file length</li> <li>Selected device (GPU is significantly faster)</li> <li>System specifications</li> </ol>"},{"location":"audio2topics/transcriber/#viewing-and-saving-transcriptions","title":"Viewing and Saving Transcriptions","text":"<ol> <li>After transcription completes, select a file from the list to view its transcription</li> <li>Click \"Save Transcription\" to export the current transcription to a text file</li> <li>Choose a location and filename in the save dialog</li> <li>The transcription will be saved as a plain text file</li> </ol>"},{"location":"audio2topics/transcriber/#whisper-models","title":"Whisper Models","text":"Model Parameters Size Relative Speed Best For tiny 39M ~75MB ~32x Quick transcriptions where accuracy is less critical base 74M ~142MB ~16x Fast transcriptions with improved accuracy small 244M ~466MB ~6x Good balance between speed and accuracy medium 769M ~1.5GB ~2x High-quality transcriptions for most use cases large 1550M ~3GB 1x Maximum accuracy for challenging audio"},{"location":"audio2topics/transcriber/#language-support","title":"Language Support","text":"<p>Whisper supports transcription in numerous languages and can automatically detect the language being spoken. Best results are achieved with:</p> <ul> <li>English</li> <li>Norwegian</li> </ul>"},{"location":"audio2topics/transcriber/#tips-for-better-results","title":"Tips for Better Results","text":"<ol> <li>Audio Quality Matters:</li> <li>Use clear recordings with minimal background noise</li> <li> <p>Higher quality audio files generally produce better transcriptions</p> </li> <li> <p>Model Selection:</p> </li> <li>Start with the \"medium\" model for a good balance of accuracy and speed</li> <li>Use \"turbo\" for best balance between spped and accuracy</li> <li>Use \"large\" for difficult audio or when maximum accuracy is needed</li> <li> <p>Use smaller models for faster processing or when resources are limited</p> </li> <li> <p>Processing Strategy:</p> </li> <li>Split very long recordings into 10-30 minute segments for better results</li> <li> <p>Test with a short sample to determine the best model for your specific audio</p> </li> <li> <p>Hardware Considerations:</p> </li> <li>GPU acceleration dramatically improves processing speed</li> <li>Larger models require more memory (RAM)</li> </ol>"},{"location":"audio2topics/transcriber/#troubleshooting","title":"Troubleshooting","text":""},{"location":"audio2topics/transcriber/#common-issues","title":"Common Issues","text":"<p>Transcription fails to start - Check for active internet connection (required for initial model download) - Try a smaller model if experiencing memory issues - Ensure sufficient disk space for model download - Restart the application and try again</p> <p>Poor transcription quality - Try a larger model (medium or large) - Check audio quality and consider pre-processing to reduce noise - For non-English content, verify language detection is working correctly - Split complex audio with multiple speakers into smaller segments</p> <p>Slow transcription - Use a CPU with more cores or enable GPU acceleration if available - Try a smaller model (base or small) - Close other resource-intensive applications while transcribing - For long files, consider splitting them into smaller chunks</p> <p>Out of memory error - Use a smaller model - Reduce batch size if transcribing multiple files - Close other applications to free up memory - Consider upgrading your system's RAM if this is a recurring issue</p>"},{"location":"audio2topics/usage/","title":"Usage","text":"<p>Coming soon! :)</p>"},{"location":"audio2topics/validator/","title":"Topic Validation Module","text":""},{"location":"audio2topics/validator/#overview","title":"Overview","text":"<p>The Topic Validation module enables you to evaluate the quality of extracted topics and determine the optimal number of topics for your document collection. It provides quantitative metrics to assess whether your topic model is effectively capturing the underlying themes in your text data.</p> <p>This module allows you to: - Measure the quality of extracted topics using multiple metrics - Find the optimal number of topics for your document collection - Visualize topic distribution and quality metrics - Make data-driven decisions to improve your topic model</p> <p>Unlike the extraction process which focuses on finding topics, validation helps you assess if those topics are good, coherent, and representative of your content.</p> <p> Main interface of the Validator Tab showing metrics and distribution</p>"},{"location":"audio2topics/validator/#core-components","title":"Core Components","text":""},{"location":"audio2topics/validator/#topicvalidator-class","title":"TopicValidator Class","text":"<p>The <code>TopicValidator</code> class serves as the main interface for validation functionality. It manages the validation and optimization processes.</p>"},{"location":"audio2topics/validator/#methods","title":"Methods","text":"Method Description Parameters Returns <code>validate_model()</code> Starts validation of a topic model <code>documents</code>: List of document strings<code>topic_model</code>: Trained topic model Returns the worker thread that can be connected to signals <code>find_optimal_topics()</code> Starts optimization to find the optimal number of topics <code>documents</code>: List of document strings<code>max_topics</code>: Maximum number of topics to consider<code>min_topic_size</code>: Minimum topic size<code>**bertopic_kwargs</code>: Additional arguments Returns the worker thread that can be connected to signals"},{"location":"audio2topics/validator/#validationworker-class","title":"ValidationWorker Class","text":"<p>The <code>ValidationWorker</code> class extends <code>QThread</code> to handle topic validation in a background thread, keeping the UI responsive during processing.</p>"},{"location":"audio2topics/validator/#signals","title":"Signals","text":"Signal Description Parameters <code>progress_updated</code> Emitted to update progress <code>int</code>: progress percentage, <code>str</code>: status message <code>validation_completed</code> Emitted when validation is done <code>dict</code>: metrics dictionary, <code>object</code>: summary DataFrame <code>error_occurred</code> Emitted when an error occurs <code>str</code>: error message"},{"location":"audio2topics/validator/#optimizationworker-class","title":"OptimizationWorker Class","text":"<p>The <code>OptimizationWorker</code> class extends <code>QThread</code> to handle finding the optimal number of topics in a background thread.</p>"},{"location":"audio2topics/validator/#signals_1","title":"Signals","text":"Signal Description Parameters <code>progress_updated</code> Emitted to update progress <code>int</code>: progress percentage, <code>str</code>: status message <code>optimization_completed</code> Emitted when optimization is done <code>dict</code>: recommendations dictionary <code>error_occurred</code> Emitted when an error occurs <code>str</code>: error message"},{"location":"audio2topics/validator/#validation-metrics","title":"Validation Metrics","text":"<p>The module calculates several key metrics to evaluate topic quality:</p>"},{"location":"audio2topics/validator/#topic-diversity-0-1","title":"Topic Diversity (0-1)","text":"<p>Measures how distinct topics are from each other based on the uniqueness of words across topics.</p> <ul> <li>High diversity (&gt;0.7): Topics have minimal overlap in keywords, indicating well-separated themes</li> <li>Low diversity (&lt;0.3): Topics share many keywords, suggesting redundancy or poorly defined topics</li> </ul>"},{"location":"audio2topics/validator/#topic-coherence-0-1","title":"Topic Coherence (0-1)","text":"<p>Measures how semantically related the words within each topic are.</p> <ul> <li>High coherence (&gt;0.7): Words in topics are strongly related, forming coherent themes</li> <li>Low coherence (&lt;0.3): Words in topics appear random or unrelated</li> </ul>"},{"location":"audio2topics/validator/#topic-coverage-0-1","title":"Topic Coverage (0-1)","text":"<p>The percentage of documents assigned to non-outlier topics (not Topic -1).</p> <ul> <li>High coverage (&gt;0.8): Most documents fit into meaningful topics</li> <li>Low coverage (&lt;0.5): Many documents don't fit into any clear topic</li> </ul>"},{"location":"audio2topics/validator/#other-metrics","title":"Other Metrics","text":"<ul> <li>Number of Topics: The total number of distinct topics (excluding the outlier topic)</li> <li>Outliers: Number of documents assigned to Topic -1 (the outlier topic)</li> <li>Topic Distribution: Count of documents assigned to each topic</li> </ul>"},{"location":"audio2topics/validator/#user-interface","title":"User Interface","text":"<p>The <code>ValidatorTab</code> class provides a comprehensive interface for validating topics and finding the optimal topic count.</p>"},{"location":"audio2topics/validator/#ui-components","title":"UI Components","text":"<ul> <li>Control Buttons:</li> <li>\"Validate Topics\" button to analyze the current topic model</li> <li> <p>\"Find Optimal Topics\" button to determine the ideal number of topics</p> </li> <li> <p>Results Tabs:</p> </li> <li>Metrics: Table showing validation metrics with color coding</li> <li>Topic Distribution: Table showing how documents are distributed across topics</li> <li> <p>Visualization: Interactive visualization of topic distribution</p> </li> <li> <p>Optimization Dialog:</p> </li> <li>Settings for maximum topics to test</li> <li>Minimum topic size control</li> <li>Progress tracking during optimization</li> <li>Results visualization showing quality scores across different topic counts</li> </ul>"},{"location":"audio2topics/validator/#usage-guide","title":"Usage Guide","text":""},{"location":"audio2topics/validator/#validating-a-topic-model","title":"Validating a Topic Model","text":"<ol> <li>Extract topics using the Topic Tab</li> <li>Navigate to the Validator Tab</li> <li>Click \"Validate Topics\" to begin the validation process</li> <li>Review the metrics in the Results tab</li> <li>Examine the topic distribution to see how documents are assigned</li> <li>Use the visualization to get a graphical view of the topic distribution</li> </ol>"},{"location":"audio2topics/validator/#finding-the-optimal-number-of-topics","title":"Finding the Optimal Number of Topics","text":"<ol> <li>Navigate to the Validator Tab</li> <li>Click \"Find Optimal Topics\" to open the optimization dialog</li> <li>Set the maximum number of topics to test (default: 15)</li> <li>Set the minimum topic size (default: 2)</li> <li>Click \"Start Optimization\" to begin the process</li> <li>Review the results, which include:</li> <li>Recommended number of topics</li> <li>Combined quality score</li> <li>Stability score</li> <li>Diversity score</li> <li>Use the visualization to see how scores vary across different topic counts</li> </ol>"},{"location":"audio2topics/validator/#understanding-optimization","title":"Understanding Optimization","text":"<p>The topic optimization process uses a sophisticated approach to find the ideal number of topics:</p> <ol> <li>Cross-Validation: For each potential topic count, it performs cross-validation by creating multiple topic models with different data splits</li> <li>Stability Measurement: It measures how consistently similar topics emerge across different data splits</li> <li>Diversity Assessment: It evaluates how distinct the topics are from each other</li> <li>Combined Scoring: It combines stability (weighted 70%) and diversity (weighted 30%) into a single quality score</li> <li>Recommendation: It recommends the number of topics with the highest combined score</li> </ol> <p>This approach balances the ability to consistently find the same topics (stability) with the need for topics to be distinct from each other (diversity).</p>"},{"location":"audio2topics/validator/#optimization-parameters","title":"Optimization Parameters","text":"<ul> <li>Maximum Topics to Test: The upper limit for how many topics to consider</li> <li>Minimum Topic Size: The minimum number of documents required for a topic</li> </ul>"},{"location":"audio2topics/validator/#interpreting-validation-results","title":"Interpreting Validation Results","text":""},{"location":"audio2topics/validator/#what-makes-a-good-topic-model","title":"What Makes a Good Topic Model?","text":"<p>A high-quality topic model typically shows: - High diversity (topics are distinct from each other) - High coherence (words within topics make sense together) - High coverage (most documents are assigned to non-outlier topics) - Balanced distribution of documents across topics</p>"},{"location":"audio2topics/validator/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"audio2topics/validator/#too-many-outliers-low-coverage","title":"Too Many Outliers (Low Coverage)","text":"<ul> <li>Problem: Many documents assigned to Topic -1 (outlier topic)</li> <li>Possible solutions:</li> <li>Decrease the minimum topic size</li> <li>Improve text preprocessing</li> <li>Try a different number of topics (use the optimization feature)</li> <li>Use a different topic modeling method</li> </ul>"},{"location":"audio2topics/validator/#low-diversity","title":"Low Diversity","text":"<ul> <li>Problem: Topics share many of the same keywords</li> <li>Possible solutions:</li> <li>Reduce the number of topics</li> <li>Improve stopword removal</li> <li>Try the BERTopic model instead of LDA or NMF</li> </ul>"},{"location":"audio2topics/validator/#imbalanced-distribution","title":"Imbalanced Distribution","text":"<ul> <li>Problem: Most documents fall into just a few topics</li> <li>Possible solutions:</li> <li>Adjust the minimum topic size</li> <li>Increase the number of topics</li> <li>Consider if the imbalance reflects your actual data</li> </ul>"},{"location":"audio2topics/validator/#tips-for-effective-validation","title":"Tips for Effective Validation","text":""},{"location":"audio2topics/validator/#validation-workflow","title":"Validation Workflow","text":"<ol> <li>Run the \"Find Optimal Topics\" feature first to get a recommended topic count</li> <li>Extract topics using the recommended count in the Topic Tab</li> <li>Validate the resulting topics</li> <li>If validation metrics show issues, adjust parameters and try again</li> <li>Consider refining topics with an LLM for better interpretability</li> </ol>"},{"location":"audio2topics/validator/#balancing-metrics-based-on-your-goals","title":"Balancing Metrics Based on Your Goals","text":"<ul> <li>For exploratory analysis: Prioritize diversity and coverage</li> <li>For content summarization: Prioritize coherence</li> <li>For document classification: Prioritize balanced topic distribution</li> </ul>"},{"location":"audio2topics/validator/#validation-with-small-document-collections","title":"Validation with Small Document Collections","text":"<ul> <li>Use smaller minimum topic sizes (1 or 2)</li> <li>Extract fewer topics (3-5 is often sufficient)</li> <li>Pay more attention to coherence than diversity</li> <li>Be aware that cross-validation results might be less reliable</li> </ul>"},{"location":"audio2topics/validator/#combining-with-other-modules","title":"Combining with Other Modules","text":"<ul> <li>Use the Visualizer to see topic relationships and keyword importance</li> <li>Try Topic Highlighting to see how topics appear in your actual documents</li> <li>Consider LLM refinement to improve topic interpretability</li> </ul>"},{"location":"audio2topics/validator/#technical-details","title":"Technical Details","text":""},{"location":"audio2topics/validator/#stability-calculation","title":"Stability Calculation","text":"<p>Topic stability is calculated by: 1. Computing topic embeddings or word distributions for topics from different data splits 2. Calculating cosine similarity between topics from different models 3. Finding the maximum similarity for each topic 4. Averaging these maximum similarities to get the overall stability score</p>"},{"location":"audio2topics/validator/#diversity-calculation","title":"Diversity Calculation","text":"<p>Topic diversity is calculated by: 1. Extracting the top N words from each topic 2. Counting the number of unique words across all topics 3. Dividing by the total number of words (accounting for repetition) 4. This produces a score between 0 and 1, where higher values indicate more diverse topics</p>"},{"location":"audio2topics/validator/#coherence-calculation","title":"Coherence Calculation","text":"<p>The module uses the coherence score from the BERTopic model, which is based on: 1. How often topic words appear together in the same documents 2. The semantic similarity of words within a topic 3. Higher coherence scores indicate more semantically related words in topics</p>"},{"location":"audio2topics/visualizer/","title":"Visualization Module","text":""},{"location":"audio2topics/visualizer/#overview","title":"Overview","text":"<p>The Visualization module enables you to create interactive and static visualizations of your text data and topic models. It provides a comprehensive suite of visualization tools that help you understand document content, explore word patterns, and interpret topic modeling results through visual representations.</p> <p>This module allows you to: - Generate word clouds and frequency charts to visualize key terms - Analyze n-gram patterns to identify common phrases - Explore topic distributions across your document collection - Visualize topic keywords and their importance - Highlight topic patterns directly in original texts - Create interactive visualizations for deep exploration of topic models - Export visualizations for presentations and reports</p> <p>Visualizations make complex text and topic data more accessible, helping to communicate insights effectively and discover patterns that might be missed in raw data.</p> <p>Main interface of the Visualizer Tab</p> <p> </p>"},{"location":"audio2topics/visualizer/#core-components","title":"Core Components","text":""},{"location":"audio2topics/visualizer/#visualizer-class","title":"Visualizer Class","text":"<p>The <code>Visualizer</code> class serves as the main interface for visualization functionality, managing the generation of visualizations using worker threads.</p>"},{"location":"audio2topics/visualizer/#methods","title":"Methods","text":"Method Description Parameters Returns <code>generate_visualization()</code> Starts generation of a visualization in a worker thread <code>viz_type</code>: Type of visualization to generate<code>data</code>: Data for the visualization<code>**kwargs</code>: Additional parameters Returns the worker thread that can be connected to signals <code>highlight_topics_in_documents()</code> Highlights topics in original text documents <code>documents</code>: List of document strings<code>topic_model</code>: Topic model<code>topic_ids</code>: List of topic IDs to highlight<code>colors</code>: List of colors for each topic List of HTML strings with highlighted topics <code>get_available_visualizations()</code> Returns available visualization types None Dictionary mapping visualization names to their types <code>save_figure()</code> Saves a figure to a file <code>fig</code>: Matplotlib figure<code>filename</code>: Output filename<code>dpi</code>: Resolution Boolean indicating success <code>figure_to_bytes()</code> Converts a figure to bytes for embedding <code>fig</code>: Matplotlib figure<code>format</code>: Output format<code>dpi</code>: Resolution Bytes containing the image data"},{"location":"audio2topics/visualizer/#visualizationworker-class","title":"VisualizationWorker Class","text":"<p>The <code>VisualizationWorker</code> class extends <code>QThread</code> to handle visualization generation in a background thread, keeping the UI responsive.</p>"},{"location":"audio2topics/visualizer/#signals","title":"Signals","text":"Signal Description Parameters <code>progress_updated</code> Emitted to update progress <code>int</code>: progress percentage, <code>str</code>: status message <code>visualization_completed</code> Emitted when visualization is done <code>object</code>: Figure object or tuple with figure and HTML <code>error_occurred</code> Emitted when an error occurs <code>str</code>: error message"},{"location":"audio2topics/visualizer/#visualization-types","title":"Visualization Types","text":"<p>The module provides various visualization types for different analytical purposes:</p>"},{"location":"audio2topics/visualizer/#text-based-visualizations","title":"Text-Based Visualizations","text":""},{"location":"audio2topics/visualizer/#word-cloud","title":"Word Cloud","text":"<p>Generates a visual representation of word frequency where word size corresponds to frequency.</p>"},{"location":"audio2topics/visualizer/#word-frequency","title":"Word Frequency","text":"<p>Creates a horizontal bar chart showing the most frequent words in the documents.</p>"},{"location":"audio2topics/visualizer/#n-grams-analysis","title":"N-grams Analysis","text":"<p>Visualizes the most common phrases (word sequences) in the documents.</p>"},{"location":"audio2topics/visualizer/#topic-based-visualizations","title":"Topic-Based Visualizations","text":""},{"location":"audio2topics/visualizer/#topic-distribution","title":"Topic Distribution","text":"<p>Shows how documents are distributed across topics using a bar chart.</p>"},{"location":"audio2topics/visualizer/#topic-keywords","title":"Topic Keywords","text":"<p>Visualizes the most important words for each topic in a grid of bar charts.</p>"},{"location":"audio2topics/visualizer/#topic-heatmap","title":"Topic Heatmap","text":"<p>Creates a heatmap showing document-topic assignments, where color intensity represents probability.</p>"},{"location":"audio2topics/visualizer/#topic-highlighting","title":"Topic Highlighting","text":"<p>Highlights topics directly in the original text documents using colored spans.</p>"},{"location":"audio2topics/visualizer/#interactive-visualizations","title":"Interactive Visualizations","text":""},{"location":"audio2topics/visualizer/#pyldavis-lda-visualization","title":"pyLDAvis (LDA Visualization)","text":"<p>Creates an interactive visualization for LDA topic models using the pyLDAvis library.</p>"},{"location":"audio2topics/visualizer/#bertopic-visualization","title":"BERTopic Visualization","text":"<p>Creates an interactive visualization for BERTopic models showing topic relationships.</p>"},{"location":"audio2topics/visualizer/#user-interface","title":"User Interface","text":"<p>The <code>VisualizerTab</code> class provides a comprehensive interface for creating, viewing, and saving visualizations.</p>"},{"location":"audio2topics/visualizer/#ui-components","title":"UI Components","text":"<ul> <li>Visualization Controls:</li> <li>Visualization type dropdown</li> <li>Parameter configuration section (changes based on selected visualization)</li> <li> <p>Generate and Save buttons</p> </li> <li> <p>Visualization Display:</p> </li> <li>Tabs for static and interactive views</li> <li>Canvas with toolbar for static visualizations</li> <li> <p>Web view for interactive visualizations</p> </li> <li> <p>Topic Highlighting Dialog:</p> </li> <li>Topic selection with color indication</li> <li>Document navigator for exploring highlighted content</li> <li>Legend showing topic colors and keywords</li> </ul>"},{"location":"audio2topics/visualizer/#usage-guide","title":"Usage Guide","text":""},{"location":"audio2topics/visualizer/#creating-visualizations","title":"Creating Visualizations","text":"<ol> <li>Select a visualization type from the dropdown menu</li> <li>Configure the visualization parameters (if applicable)</li> <li>Click \"Generate Visualization\" to create the visualization</li> <li>The visualization will appear in the main viewing area</li> <li>Interactive visualizations will appear in the \"Interactive View\" tab</li> </ol>"},{"location":"audio2topics/visualizer/#customizing-visualizations","title":"Customizing Visualizations","text":"<p>Each visualization type offers specific customization options:</p>"},{"location":"audio2topics/visualizer/#word-cloud_1","title":"Word Cloud","text":"<ul> <li>Language: Select the text language for better processing</li> <li>Color Scheme: Choose from various color palettes</li> </ul>"},{"location":"audio2topics/visualizer/#word-frequency_1","title":"Word Frequency","text":"<ul> <li>Number of Words: Set how many top words to display</li> <li>Language: Select the text language</li> </ul>"},{"location":"audio2topics/visualizer/#n-grams-analysis_1","title":"N-grams Analysis","text":"<ul> <li>N-gram Size: Set the size of word sequences (2=bigrams, 3=trigrams)</li> <li>Number of N-grams: Set how many top phrases to display</li> <li>Language: Select the text language</li> </ul>"},{"location":"audio2topics/visualizer/#topic-keywords_1","title":"Topic Keywords","text":"<ul> <li>Words per Topic: Set how many words to show for each topic</li> <li>Color Scheme: Choose from various color palettes</li> </ul>"},{"location":"audio2topics/visualizer/#topic-highlighting_1","title":"Topic Highlighting","text":"<ul> <li>Select Topics: Choose which topics to highlight</li> <li>Color Scheme: Select a color palette for topic differentiation</li> </ul>"},{"location":"audio2topics/visualizer/#interactive-lda","title":"Interactive LDA","text":"<ul> <li>MDS Algorithm: Choose between t-SNE and PCoA for dimensionality reduction</li> </ul>"},{"location":"audio2topics/visualizer/#bertopic-visualization_1","title":"BERTopic Visualization","text":"<ul> <li>Number of Topics: Set how many topics to include in the visualization</li> </ul>"},{"location":"audio2topics/visualizer/#navigating-visualizations","title":"Navigating Visualizations","text":"<p>The interface provides several tools for exploring visualizations:</p> <ul> <li>Zoom and Pan: Use the toolbar below visualizations to zoom in/out and pan</li> <li>Reset View: Click the home button in the toolbar to reset the view</li> <li>Interactive Elements: For interactive visualizations, click on elements for details</li> <li>Smooth Scrolling: Scroll smoothly through large visualizations with optimized controls</li> </ul>"},{"location":"audio2topics/visualizer/#saving-visualizations","title":"Saving Visualizations","text":"<ol> <li>Click \"Save Visualization\" to export your visualization</li> <li>For static visualizations (word clouds, charts, etc.):</li> <li>Choose from PNG, JPEG, PDF, or SVG formats</li> <li>Set the filename and location</li> <li>For interactive visualizations (pyLDAvis, BERTopic):</li> <li>Save as HTML for interactive viewing in any web browser</li> <li>The HTML file contains the complete interactive visualization</li> </ol>"},{"location":"audio2topics/visualizer/#visualization-selection-guide","title":"Visualization Selection Guide","text":"Visualization Type Best Used For Requirements Word Cloud Quick overview of key terms, presentations Text documents Word Frequency Precise word frequency analysis Text documents N-grams Identifying common phrases and expressions Text documents Topic Distribution Understanding topic prevalence Topic model results Topic Keywords Interpreting topic meaning Topic model results Topic Heatmap Analyzing document-topic relationships Topic model results Topic Highlighting Validating topics in original context Topic model and documents Interactive LDA Deep exploration of LDA topic models LDA topic model BERTopic Visualization Interactive exploration of BERTopic models BERTopic model"},{"location":"audio2topics/visualizer/#tips-for-effective-visualization","title":"Tips for Effective Visualization","text":""},{"location":"audio2topics/visualizer/#general-visualization-tips","title":"General Visualization Tips","text":"<ol> <li>Choose the right visualization for your specific analytical goal</li> <li>Use consistent color schemes across related visualizations</li> <li>Balance detail and clarity - sometimes less information is more effective</li> <li>Consider your audience - simpler visualizations for non-technical viewers</li> <li>Combine multiple visualization types for comprehensive understanding</li> </ol>"},{"location":"audio2topics/visualizer/#word-based-visualizations","title":"Word-Based Visualizations","text":"<ul> <li>Remove common stopwords before visualization for clearer results</li> <li>For technical content, preserve domain-specific terms</li> <li>Compare n-grams with single words to capture multi-word concepts</li> <li>Consider stemming or lemmatization for more concise visualizations</li> </ul>"},{"location":"audio2topics/visualizer/#topic-based-visualizations_1","title":"Topic-Based Visualizations","text":"<ul> <li>Exclude outlier topics (-1) for cleaner visualizations</li> <li>Use topic highlighting to validate model quality in original text</li> <li>Compare topic distribution with topic coherence metrics</li> <li>Use LLM-refined topic labels for more interpretable visualizations</li> </ul>"},{"location":"audio2topics/visualizer/#for-presentations","title":"For Presentations","text":"<ul> <li>Word clouds and simple bar charts are most accessible to general audiences</li> <li>Use consistent color coding across visualizations for topics</li> <li>Include examples of highlighted text to show topics in context</li> <li>Save as high-resolution images (300 DPI or higher) for print materials</li> </ul>"},{"location":"audio2topics/visualizer/#technical-notes","title":"Technical Notes","text":""},{"location":"audio2topics/visualizer/#smooth-scrolling-and-performance","title":"Smooth Scrolling and Performance","text":"<p>The interface includes optimizations for smooth performance:</p> <ul> <li>Pixel-based scrolling for smoother navigation</li> <li>Reduced scroll sensitivity for finer control</li> <li>Optimized rendering for large visualizations</li> <li>Hardware acceleration when available</li> </ul>"},{"location":"audio2topics/visualizer/#model-compatibility","title":"Model Compatibility","text":"<ul> <li>pyLDAvis works best with LDA models but can display warnings with others</li> <li>BERTopic visualizations require a BERTopic model with embedding data</li> <li>Topic highlighting works with all model types but with varying accuracy</li> </ul>"},{"location":"audio2topics/visualizer/#file-formats","title":"File Formats","text":"<p>When saving visualizations, different formats offer different advantages:</p> <ul> <li>PNG: Good general-purpose format, suitable for presentations</li> <li>JPEG: Smaller file size but lower quality for text</li> <li>PDF: Vector format, excellent for publication</li> <li>SVG: Vector format, good for further editing</li> <li>HTML: Required for interactive visualizations</li> </ul>"},{"location":"data_insightron/","title":"Overview","text":""},{"location":"data_insightron/#datainsightron-package","title":"<code>DataInsightron</code> Package \ud83e\udd16","text":"<p><code>DataInsightron</code>\ud83e\udd16 is a Python package designed to provide a comprehensive overview of a dataset characteristics. It computes a variety of metrics\u2014ranging from basic dimensions, Features related metrics, Quality metrics, possible best-performing ML algorithm in prediction tasks, Computational resources requirements, and Complexity measure. <code>DataInsightron</code> is desigend to guide you fully undertand your dataset as a whole. The package is particularly helpful in the exploratory data analysis (EDA) phase, as it automates the extraction of numerous data descriptors that would otherwise be computed through multiple manual steps.</p> <p>Coming soon! :)</p>"},{"location":"data_insightron/api/","title":"<code>DataInsightron</code> \ud83e\udd16","text":"<p>Coming soon! :)</p>"},{"location":"data_insightron/usage/","title":"Usage Guide","text":"<p>Coming soon! :) </p>"},{"location":"modularity_encoding/","title":"Overview","text":""},{"location":"modularity_encoding/#modularity-encoding-package","title":"<code>Modularity Encoding</code> Package \ud83d\udee0\ufe0f\ud83d\udce6","text":"<p>The <code>modularity_encoding</code> package provides functionality for grouping high dimensional Health Coding Systems (HCSs). In the medical domain, these code systems can be challenging to handle in big datasets while implementing machine learning model for classification or prediction purposes. Examples of these code systems are International Classification of Diseases (ICD) codes, Anatomical Therapeutic Chemical (ATC) codes, Diseases Related Group (DRG) codes, etc. These code systems include thousands of codes and binarizing them in many columns will greatly increase the sparsity of the dataset leading to worse model performances. More specifically, the package includes functions for creating a network of code systems on the co-occurrences of the code systems codes in the dataset population, then, detecting communities(modules) within the network. These modules are a way to group the codes in a clinically-relevant and data-driven way. After that, the package provide a new column which assigns the code system codes to their corresponding community modules. By this way, the model dimensions will be significantly reduced  form thousands to a handful number of dimensions.</p>"},{"location":"modularity_encoding/#key-features","title":"Key Features","text":"<ul> <li>Network Creation: The package creates a network from the HCSs codes based on their co-occurrences within a dataset.</li> <li>Community Detection: It identifies communities (or modules) within the network. These communities group the HCSs codes in a way that is both clinically relevant and data-driven, enhancing the interpretability and utility of the codes.</li> <li>Dimensionality Reduction: By assigning codes to their respective community modules, <code>modularity_encoding</code> significantly reduces the dimensionality of the data\u2014from potentially thousands of columns to just a few. This reduction helps in managing dataset sparsity and improving model performance.</li> </ul>"},{"location":"modularity_encoding/#license","title":"License","text":"<p>Released under the MIT License: Copyright (C) 2024 modularity_encoding</p> <p>Developed by: Mohsen Askar ceaser198511@gmail.com</p>"},{"location":"modularity_encoding/#citation","title":"Citation","text":"<p>If you use <code>modularity_encoding</code> in your research, we would appreciate a citation to this paper:</p> <p>\u201cUsing Network Analysis Modularity to Group Health Code Systems and Decrease Dimensionality in Machine Learning Models\u201d https://doi.org/10.1016/j.rcsop.2024.100463</p>"},{"location":"modularity_encoding/api/","title":"API Reference","text":""},{"location":"modularity_encoding/api/#functions-overview","title":"Functions Overview","text":"<p>The <code>modularity_encoding</code> package comprises One main function and five supplementary functions. These functions can either be used together in a pipeline for detailed control and inspection or executed all at once using the main function for convenience.</p>"},{"location":"modularity_encoding/api/#main-function","title":"Main Function","text":"<ul> <li><code>modularity_encode</code>: Executes the full modularity encoding workflow in a single call. This function is ideal for users who need a straightforward and quick way to apply the encoding to their dataset.</li> </ul>"},{"location":"modularity_encoding/api/#supplementary-functions","title":"Supplementary Functions","text":"<p>These functions are designed for users who prefer to manually handle each step of the process, allowing for greater flexibility and inspection at each stage:</p> <ul> <li><code>create_code_system_network</code>: Constructs a network from the health coding system codes based on their occurrences within a dataset.</li> <li><code>detect_code_system_communities</code>: Identifies communities (or modules) within the created network.</li> <li><code>encode_code_system_to_module</code>: Assigns each code in the dataset to the detected community module, effectively reducing the dimensionality of the dataset.</li> <li><code>print_edge_list</code>: Outputs a list of edges from the network, useful for debugging or detailed analysis.</li> <li><code>assign_module</code>: Assigns and records the module for each code system code in the dataset.</li> </ul>"},{"location":"modularity_encoding/api/#the-main-function-modularity_encode","title":"The main function <code>modularity_encode</code>","text":"<p>The <code>modularity_encode</code> function is used to execute the whole flow in one line of code. It takes in a pandas data frame data that contains patient data with a code_system column.</p>"},{"location":"modularity_encoding/api/#parameters","title":"Parameters:","text":"<ul> <li>data (<code>pd.DataFrame</code>): The input data.</li> <li>code_system_col (<code>str</code>, optional): Column name representing the code system. Defaults to 'code_system'.</li> <li>patientid_col (<code>str</code>, optional): Column name representing the patient ID. Defaults to 'patientid'.</li> <li>resolution (<code>float</code>, optional): Granularity of the community detection. Defaults to 1.0.</li> <li>random_state (<code>int</code>, optional): Seed for the random number generator. Defaults to 42.</li> <li>output_col (<code>str</code>, optional): Column name where the module numbers will be saved. Defaults to 'module_number'.</li> </ul>"},{"location":"modularity_encoding/api/#returns","title":"Returns:","text":"<ul> <li>tuple:</li> <li>G (<code>nx.Graph</code>): The code system network graph.</li> <li>data (<code>pd.DataFrame</code>): Updated data with a new column containing module numbers for each code system.</li> </ul> <pre><code>import pandas as pd\n# Import the dataset (example dataset)\ndata = pd.DataFrame({\n    'patientid': [1, 1, 2, 2],\n    'code_system': ['J15', 'B24', 'I50', 'F06']\n})\nG, processed_data= me.modularity_encode(data, code_system_col='code_system', patientid_col='patientid', resolution=1.0, random_state=42, output_col='module_number')\n</code></pre> <pre><code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 5996.15it/s]\n</code></pre> <p>The first function will do the full work. If the user wants to perform the encoding step by step, the following functions can be followed.</p>"},{"location":"modularity_encoding/api/#the-second-function-create_code_system_network","title":"The second function <code>create_code_system_network</code>","text":"<p>The <code>create_code_system_network</code> function is used to create a network of code systems based on patient data. It takes in a pandas data frame data that contains patient data with a code_system column and returns a NetworkX graph object G. The network is represented in nodes and edges. The nodes are the code of the code_system , for examples ICD-10 codes, and the edges between the nodes will represent the number of patients who had this pair of ICD-10 codes.</p>"},{"location":"modularity_encoding/api/#parameters_1","title":"Parameters:","text":"<p>The function takes 3 arguments:</p> <ul> <li>data (<code>pd.DataFrame</code>): the defined dataset</li> <li>code_system_col (<code>str</code>, optional): which defines the column contain the code system </li> <li>patientid_col (<code>str</code>, optional): which defines the patients ids in a longitudinal format. </li> </ul> <p>The function will count the number of patients combined each pair of code system codes and define that as the edges of the network while the nodes wil be the code system codes themselves as mentioned before. The fuction can be called as follows:</p> <pre><code>G = me.create_code_system_network(data, code_system_col='code_system', patientid_col='patientid')\n</code></pre> <pre><code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;?, ?it/s]\n</code></pre> <p>The resulted network (G) is a NetworkX object and different commands of NetworkX can be applied on it by importing NetworkX module.</p>"},{"location":"modularity_encoding/api/#the-third-function-detect_code_system_communities","title":"The third function  <code>detect_code_system_communities</code>","text":"<p>The <code>detect_code_system_communities</code> function is used to detect communities within the code system network. It takes in a NetworkX graph object G and an optional random_state parameter for reproducibility and returns a dictionary code_system_to_module that maps each code system to its corresponding module number. The package uses the Louvain method described in Fast unfolding of communities in large networks, Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, Renaud Lefebvre, Journal of Statistical Mechanics: Theory and Experiment 2008(10), P10008 (12pp). The package \"community\" https://github.com/taynaud/python-louvain and https://python-louvain.readthedocs.io/en/latest/api.html is used to detect the modules.</p> <p>The modules can be interpreted as a cluster of code of code system which has denser connection among them than the rest of the network. As we build the network on the occurrences of these codes between patients, the modules can be interpreted as these codes of the code system tend to frequently cooccur in reality. For example if we use ICD codes (diagnoses), the modules will reveal the multimorbidity patterns in the dataset population, whereas if we use the ATC codes (medications), the modules will represent the comedication patterns in the dataset population.</p>"},{"location":"modularity_encoding/api/#parameters_2","title":"Parameters:","text":"<ul> <li>G:the network created in the first function <code>create_code_system_network</code></li> <li>random_state:int, default(None), (optional) The parameter will assign a fixes random_state value.</li> <li>resolution: double, default =1, (optional).  The resolution of modularity detection can be modified in the paramerte \"resolution\" which will change the size of modules.  The default value is 1. represents the time described in \u201cLaplacian Dynamics and Multiscale Modular Structure in Networks\u201d, R. Lambiotte, J.-C. Delvenne, M. Barahona.</li> </ul> <p>The function can be called as follows:</p> <pre><code>modules = me.detect_code_system_communities(G, random_state=42, resolution=1)\nmodules\n</code></pre> <pre><code>{'B24': 0, 'J15': 0, 'F06': 1, 'I50': 1}\n</code></pre>"},{"location":"modularity_encoding/api/#the-fourth-function-encode_code_system_to_module","title":"The fourth function <code>encode_code_system_to_module</code>","text":"<p>The <code>encode_code_system_to_module</code> function is used to encode the code systems in a pandas data frame data to their corresponding module numbers based on the \"code_system_to_module\" dictionary returned from \"detect_code_system_communities\". It returns the original dataset with an additional column which indicates the module number this code belong to in the network.</p>"},{"location":"modularity_encoding/api/#parameters_3","title":"Parameters:","text":"<ul> <li>data: the network created in the first function <code>create_code_system_network</code></li> <li>modules: defines the modules detected in the second function \"detect_code_system_communities\"</li> <li>output_col: specifies the desired name of the added column, by default the column name is module_numnber unless changed.</li> </ul> <p>It is imporatant to change the column name after the argument \"output_col\" if the used will perform modularity encoding on more than one code system in the same dataset to prevent overwriting the same column. </p> <p>The function can be called as follows:</p> <pre><code>encoded_data = me.encode_code_system_to_module(data, modules, output_col='my_module_number')\nencoded_data\n</code></pre> patientid code_system module_number my_module_number 0 1 J15 0 0 1 1 B24 0 0 2 2 I50 1 1 3 2 F06 1 1 <p>Once the user have this column, it can be used in the model as it will have much less categories (dimensions), alternativlely it can be dummy encoded to binary variables or by other methods of encoding and won't cause much dispersity in the dataset.</p>"},{"location":"modularity_encoding/api/#the-fifth-function-print_edge_list","title":"The fifth function <code>print_edge_list</code>","text":"<p>The function <code>print_edge_list</code> will save the the network's edgelist in a csv file in the same work directory. The funtion takes two arguments: </p> <ul> <li>G (<code>nx.Graph</code>): the graph object (G) </li> <li>The CSV filename (<code>pd.DataFrame</code>), example (edgelist.csv)</li> </ul> <p>The function can be called as follows:</p> <pre><code>print_edge_list = me.print_edge_list(G, \"edgelist.csv\")\n</code></pre> <pre><code>Edge list saved to file: edgelist.csv\n</code></pre> <pre><code>edgelist = pd.read_csv('edgelist.csv')\nedgelist.head()\n</code></pre> source target weight 0 B24 J15 1 1 F06 I50 1"},{"location":"modularity_encoding/api/#the-sixth-function-assign_module","title":"The sixth function <code>assign_module</code>","text":"<p>The <code>assign_module</code> function maps a given code (or a list of codes) from the studied code system to its corresponding module. This function is especially useful when the user wishes to make new predictions and needs to find the corresponding encoding integer of a code in the code system.</p>"},{"location":"modularity_encoding/api/#parameters_4","title":"Parameters:","text":"<ul> <li>codes (<code>str</code>): The code(s) from the code system that the user wants to map to a module. These codes should exist in the original dataset.</li> <li>modules (<code>dict</code>): A dictionary containing mappings from codes to modules, generated from the function <code>detect_code_system_communities</code>.</li> </ul>"},{"location":"modularity_encoding/api/#returns_1","title":"Returns:","text":"<ul> <li>If the code(s) exists in the dictionary, the function returns the corresponding module.</li> <li>If the code(s) does not exist in the dictionary, the function returns an appropriate error message indicating that the code is not present in the code-system-to-module mapping.</li> </ul>"},{"location":"modularity_encoding/api/#assumptions","title":"Assumptions","text":"<ul> <li>The function assumes that the code entered is a string value and that it presented in the code system to module mapping (i.e. the original dataset).</li> </ul> <p>The function can be called as follows:</p> <pre><code># for one code \ncode = \"J15\" # example\nmodule_of_the_code = me.assign_module(code, modules) \nprint('The module containig this code is module:',module_of_the_code)\n</code></pre> <pre><code>The module containig this code is module: 0\n</code></pre> <pre><code># for multiple codes\ncodes = [\"J15\", \"B24\", \"A11\"] # example\nmodule_of_the_codes = me.assign_module(codes, modules) \nprint('The modules list containing these codes:',module_of_the_codes)\n</code></pre> <pre><code>The modules list containing these codes: [0, 0, \"The entered code 'A11' is not present in the code system to module mapping.\"]\n</code></pre>"},{"location":"modularity_encoding/api/#user-example","title":"User example","text":"<p>Here's a full example of how to use the <code>modularity_encoding</code> package:</p> <pre><code>import modularity_encoding.functions as me\nimport pandas as pd\n\n# import you dataset\ndata = pd.DataFrame({\n    'patientid': [1, 1, 2, 2],\n    'code_system': ['J15', 'B24', 'I50', 'F06']\n})\n\n# one function \nG, processed_data= me.modularity_encode(data, code_system_col='code_system', patientid_col='patientid', resolution=1.0, random_state=42, output_col='module_number')\n# save the data with the new column\nprocessed_data.to_csv('processed_data.csv', index=False)\n# print or save the edgelist\nme.print_edge_list(G, \"edgelist.csv\")\n\n# Consecutive functions (must be run in this order)\n# create the network \nG = me.create_code_system_network(data, code_system_col='code_system', patientid_col='patientid')\n\n# detect the modules in the network \nmodules = me.detect_code_system_communities(G, random_state=42,resolution=1) # change resolution if needed\n\n# assign the codes of the targeted code system to their correponding module id \nencoded_data = me.encode_code_system_to_module(data, modules, output_col='my_module_number')\n\n# print the data\nprint(data)\n\n# print th network's edgelist  \nprint_edge_list = me.print_edge_list(G, \"edgelist.csv\")\n# in case of implementing the function on other code system in the same dataset remember to specify the new \"code_system_col\" \n# and to change the \"output_col\" name. \n\n# To make new prediction the user can use this function to map the code in the code system to its correponding module\n# map codes' modules to make new predictions\ncode = \"J15\"\nmodule_of_the_code = me.assign_module(code, modules) \nprint(module_of_the_code)\n\n# for multiple codes\ncodes = [\"J15\", \"B24\", \"A11\"] # example\nmodule_of_the_codes = me.assign_module(codes, modules) \nprint('The modules list containing these codes:',module_of_the_codes)\n</code></pre> <pre><code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;?, ?it/s]\n\n\nEdge list saved to file: edgelist.csv\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;?, ?it/s]\n\n   patientid code_system  module_number  my_module_number\n0          1         J15              0                 0\n1          1         B24              0                 0\n2          2         I50              1                 1\n3          2         F06              1                 1\nEdge list saved to file: edgelist.csv\n0\nThe modules list containing these codes: [0, 0, \"The entered code 'A11' is not present in the code system to module mapping.\"]\n</code></pre>"},{"location":"modularity_encoding/api/#faq","title":"FAQ","text":"<p>1. What is this package used for?</p> <p>This package provides a set of functions to create a network from patient data, detect communities in the network, and encode the code systems to their corresponding module numbers. It can be used for analyzing patterns and relationships among different medical code systems in patient data.</p> <p>2. What are some common use cases for this package?</p> <p>The package can be used to group any code system that can be aggragted on a level (for example the patient level). It is especially useful for high-dimensional code systems such as the International Classification of Diseases (ICD) codes, Anatomical Therapeutic Chemical (ATC) codes, Diseases Related Group (DRG) codes in the health domain, Current Procedural Terminology (CPT) codes, and Systematized Nomenclature of Medicine (SNOMED) codes. </p> <p>3. What is a code system?</p> <p>A code system is a standardized system of codes used to represent medical concepts, such as diagnoses, procedures, and medications. Examples of code systems include ICD-10, CPT, ATC, RxNorm, etc.</p> <p>4. What is a network?</p> <p>In the context of this package, a network is a graph representation of the relationships among different code systems based on the number of shared patients. Each code system is a node, and the number of shared patients between two code systems is the weight of the edge between them.</p> <p>5. What is a community in a network?</p> <p>A community in a network is a group of nodes that are more densely connected to each other than to the rest of the network. In the context of this package, a community represents a group of code systems that tend to co-occur in patients more frequently than with the other codes in the code systems.</p> <p>6. What is module encoding?</p> <p>Module encoding is the process of mapping each code system to its corresponding community module number. This allows for easier analysis and visualization of the relationships among code systems in the network.</p> <p>7. How do I install this package?</p> <p>The package can be installed using <code>pip</code> install. The package dependencies (see above) have to be installed as well.</p> <p>8. What format does the input data need to be in?</p> <p>The input data needs to be a Pandas DataFrame with columns for patient IDs and code systems. The column names for these two columns can be specified as arguments to the <code>create_code_system_network</code> function.</p> <p>9. What is the output of the <code>detect_code_system_communities</code> function?</p> <p>The output of this function is a dictionary that maps each code system to its corresponding community module number.</p> <p>10. What is an edge list?</p> <p>An edge list is a way of representing the edges (connections) between nodes (points) in a network. It is a table with three columns representing tha pair of nodes that are connected in the network and a third column representing the weight of the connections, which in this case is the number of patients who share the nodes. The edge list can be used to create a visualization of the network or to perform further analysis using other software tools.</p> <p>11. How do I save the network as an edge list?</p> <p>The <code>print_edge_list</code> function to save the network as an edge list in a CSV file in the same working directory. By default, the CSV file name is \"edgelist.csv\" but the name can be specified as an argument in the function.</p> <p>12. How can I implement other network measures on the created Netwrok?</p> <p>The created Network is a NetworkX object , which means that all measures implemented in NetworkX package can be applied on the created network by importing NetworkX.</p> <p>13. How can I visualize the network created by the <code>create_code_system_network</code> function?</p> <p>As mentioned, the function returns a NetworkX graph object, which can be visualized using the built-in plotting functions provided by the networkx and matplotlib libraries. You can also export the graph as an edge list using the print_edge_list() function and use external tools to create custom visualizations such as Gephi.</p> <p>14. How can I interpret the module numbers assigned by the <code>detect_code_system_communities</code> function?</p> <p>The <code>detect_code_system_communities</code> function uses the Louvain method to identify groups of related code systems based on their shared patients. Each module is assigned a unique integer label, which can be used to group code systems together for further analysis. The meaning of the module labels will depend on the specific dataset and application and the used code system.</p> <p>15. Can this package be used with data from any type of healthcare provider or system?</p> <p>Yes, as long as the data is in a format that can be read by Pandas and the necessary columns are included in the input data.</p> <p>16. Are there any limitations to the size of dataset that can be analyzed using this package?</p> <p>The size of the dataset that can be analyzed will depend on the hardware available and the specific use case. However, this package includes optimizations such as using <code>NetworkX</code> graphs to efficiently represent and analyze the data, and using <code>tqdm</code> library to display progress bars during processing.</p> <p>17.In case of making new predictions, how can I determine the assigned module for the code system?</p> <p>You can use the <code>assign_module</code> function to map the code to its correpoding module interger id (corresponds to the encdoing number of this code). The code entered must be a string value and must have been in the original dataset.</p>"},{"location":"modularity_encoding/usage/","title":"Usage Guide","text":""},{"location":"modularity_encoding/usage/#dependencies","title":"Dependencies","text":"<p>The <code>modularity_encoding</code> package relies on some external libraries, which need to be installed first:</p> <ul> <li><code>pandas</code>: Used for handling and manipulating the dataset.</li> <li><code>networkx</code>: Facilitates the creation and manipulation of complex networks of code systems.</li> <li><code>itertools</code>: Helps in efficient looping for combinations and permutations needed in module detection.</li> <li><code>python-louvain</code>: Essential for detecting communities within the network.</li> <li><code>tqdm</code>: Provides progress bars to loops to visualize the computation time.</li> <li><code>matplotlib</code>: Required for plotting networks and other visualizations to understand the data better.</li> </ul>"},{"location":"modularity_encoding/usage/#installation","title":"Installation","text":"<p>The <code>modularity_encoding</code> package can be installed using <code>pip</code>:</p> <pre><code>!pip install modularity_encoding==0.1\n</code></pre>"},{"location":"modularity_encoding/usage/#importing","title":"Importing","text":"<p>The package is imported as follows:</p> <pre><code>import modularity_encoding.functions as me\n</code></pre>"},{"location":"mydataviewer-GUI/","title":"Overview","text":""},{"location":"mydataviewer-GUI/#my-dataviewer-package","title":"<code>My DataViewer</code> Package \ud83d\udda5\ufe0f","text":"<p><code>My DataViewer</code> : A Lightweight Real-Time Interactive Data Viewer IDE for Python</p> <p>Inspired by the Stata <code>browser</code>,<code>My DataViewer</code> is a lightweight, interactive data viewer IDE for Pyhton built with <code>PyQt5</code>, designed for real-time manipulation and exploration of pandas DataFrames. Featuring real-time reflection of changes to your datasets, <code>My DataViewer</code> offers a lightweight, intuitive way to explore and analyze full dataframes.  </p> <p>An Overview of <code>browse</code> in Stata - <code>browse</code> in Stata opens a window that displays your dataset in a spreadsheet-like view. It allows you to see the dataset, scroll through it, and interactively examine variables and their values.</p> <p>Interactivity in Stata's <code>browse</code>:</p> <ul> <li> <p>Live, Real-time Reflection: Any changes you make to the dataset (e.g., adding variables, modifying values) are automatically reflected in the <code>browse</code> window without needing to close and reopen the window.</p> </li> <li> <p>Read-Only by Default: The browse command is read-only by default, so you can\u2019t modify values directly in the viewer unless you switch to edit mode.</p> </li> <li> <p>View Subsets of Data: You can specify subsets of the data to view (e.g., certain variables or observations).</p> </li> </ul> <p>Integrated features in <code>My DataViewer</code> package:</p> <ul> <li>Real-time dataset updates: Automatically reflects changes in the DataFrame as you manipulate it.</li> <li>Embedded <code>IPython console</code>: Execute Python code and interact with your data directly within the viewer.</li> <li>Search and filter dataframe: Easily search and filter your data, with results reflected in real time.</li> <li>Check and scroll through the whole dataframe: Allows the user to inspect the whole dataframe ensuring the changes are correctly executed.</li> <li>Custom themes and fonts: Switch between selected themes and fonts for a personalized experience.</li> <li>Split-view layout: Includes a variable table and the main data view, allowing for easy navigation of variables and their types.</li> </ul> <p>A quick comaprison between Stata <code>browse</code> and RStudio <code>View()</code></p> Feature Stata browse RStudio View() Real-time reflection of changes Yes \u2014 automatically updates with changes No \u2014 requires a manual refresh (View() again) Read-Only by default Yes (but can switch to edit mode) Yes (no edit mode available) Interactive editing Yes, if you switch to edit mode No Filtering/Subset view Yes, allows viewing subsets of variables/rows Requires filtering beforehand, not interactive Customizable views Yes, can display specific columns/rows Requires code to subset data, then view Viewer format Standalone window (outside the main Stata UI) Integrated as a tab within RStudio"},{"location":"mydataviewer-GUI/#a-comparison-with-stata-browse-rstudio-view-and-my-dataviewer","title":"A comparison with Stata <code>browse</code>, RStudio <code>View()</code>, and <code>My DataViewer</code>","text":"Feature Stata <code>browse</code> RStudio <code>View()</code> <code>My DataViewer</code> package Real-time reflection of changes Yes \u2014 automatically updates with data changes No \u2014 must manually refresh the view Yes \u2014 real-time updates are supported via observable DataFrame Read-Only by default Yes (can switch to <code>edit</code> mode) Yes (no direct editing in the viewer) Yes, read-only but with real-time updates Interactive editing Yes, if you switch to <code>edit</code> mode No No direct editing in the viewer, editing must be done programmatically Viewing subsets of data Yes, easily view subsets of variables/rows Yes, but requires filtering the data manually Yes, filtering implemented using search functionality in real time Window integration Standalone window (outside Stata\u2019s main interface) Integrated tab in RStudio Integrated window in PyQt5, with split views and dockable widgets Sorting and filtering in viewer Yes, sortable columns and filter rows interactively Limited sorting/filtering functionality Yes, with header-click sorting and real-time search and filtering Customizable views Yes, can select specific columns/rows Requires prior filtering in code Customizable through filtering and real-time search features Console integration No embedded console No embedded console Yes, embedded IPython console for live data manipulation Custom themes No No Yes, switchable light/dark themes and custom fonts Jupyter integration No No Yes, updates Jupyter kernel namespace if running inside Jupyter"},{"location":"mydataviewer-GUI/#license","title":"License","text":"<p>Released under the MIT License: Copyright (C) 2024 <code>mydataviewer-GUI</code></p> <p>Developed by: Mohsen Askar  ceaser198511@gmail.com</p>"},{"location":"mydataviewer-GUI/api/","title":"API Reference","text":""},{"location":"mydataviewer-GUI/api/#my-dataviewer-components","title":"<code>My DataViewer</code> components","text":"<ol> <li><code>data_import_dialog.py</code>: Manages data import imports using PyQt. The imported data could be in \".csv\", \".excel\", \".json\", \".sql\", \".api\", or \".dta\".</li> <li><code>data_viewer.py</code>: Contains the <code>DataViewer</code> class, which provides the core GUI using PyQt. It handles table views, search functionality, variable tables, themes, fonts, and a console.</li> <li><code>dataframe_model.py</code>: Defines <code>DataFrameModel</code>, which is the model for the table view and supports pagination, sorting, and updating based on an observable DataFrame.</li> <li><code>observable_dataframe.py</code>: Extends <code>pandas.DataFrame</code> into an <code>ObservableDataFrame</code> that triggers callbacks on changes, allowing the UI to stay in sync.</li> <li><code>view_dataframe.py</code>: Defines the main <code>view_dataframe</code> function that launches the DataViewer with the provided DataFrame, handling the GUI's event loop.</li> <li><code>themes.py</code>: Contains style sheets for light, dark, and solarized dark themes, which are applied to the PyQt widgets.</li> </ol>"},{"location":"mydataviewer-GUI/api/#working-with-jupyter-qtconsole","title":"Working with Jupyter QtConsole","text":"<ul> <li>As stated in its documentation \"The Qt console is a very lightweight application that largely feels like a terminal, but provides a number of enhancements only possible in a GUI, such as inline figures, proper multi-line editing with syntax highlighting, graphical calltips, and much more.\"</li> <li>The embedded IPython console provides an interactive environment to manipulate your DataFrame. You can perform operations such as filtering rows, applying transformations, or generating statistics directly from within the console. Any changes made in the console are immediately reflected in the table view, ensuring real-time feedback</li> <li>The user can activate the desired environment using <code>conda activate</code>.</li> <li>By default the loaded dataframe is named <code>df</code>.</li> <li>See the documentaion here: https://qtconsole.readthedocs.io/en/stable/</li> </ul>"},{"location":"mydataviewer-GUI/api/#additional-resources","title":"Additional Resources","text":"<ul> <li>PyQt5 Documentation: https://www.riverbankcomputing.com/static/Docs/PyQt5/</li> <li>qtconsole Documentation: https://qtconsole.readthedocs.io/en/latest/</li> </ul>"},{"location":"mydataviewer-GUI/usage/","title":"Usage Guide","text":""},{"location":"mydataviewer-GUI/usage/#1-my-dataviewer-package-installation","title":"1. <code>My DataViewer</code> package installation","text":"<p>Install from PyPI using <code>pip</code></p> <pre><code>!pip install mydataviewer-GUI\n</code></pre>"},{"location":"mydataviewer-GUI/usage/#2-package-dependencies","title":"2. Package dependencies","text":"<ul> <li>Python 3.6 or newer</li> <li>Pandas</li> <li>PyQt5</li> <li>qtconsole</li> <li>ipykernel</li> <li>jupyter_client</li> </ul>"},{"location":"mydataviewer-GUI/usage/#3-how-to-start-my-dataviewer","title":"3. How to start <code>My DataViewer</code>","text":""},{"location":"mydataviewer-GUI/usage/#a-running-the-package-from-the-terminal-using-viewdata-a-command","title":"A. Running the Package from the Terminal using <code>viewdata</code> a command","text":"<p>After installing the package using <code>pip install mydataviewer</code>, you can launch the <code>My DataViewer</code> directly from the terminal using the command-line interface (CLI).</p>"},{"location":"mydataviewer-GUI/usage/#steps","title":"Steps:","text":"<ol> <li>Open a terminal window.</li> <li>Activate the environment in which <code>My DataViewer</code> is installed, <code>conda activate my_env</code>.</li> <li>Run the following command to start the <code>My DataViewer</code>:</li> </ol> <pre><code>viewdata\n</code></pre>"},{"location":"mydataviewer-GUI/usage/#b-running-my-dataviewer-from-the-terminal-using-a-python-file","title":"B. Running <code>My DataViewer</code> from the terminal using a python file","text":"<p>You can also launch the <code>My DataViewer</code> directly from the terminal by running a custom python file.</p>"},{"location":"mydataviewer-GUI/usage/#steps_1","title":"Steps:","text":"<ol> <li>Create a python file, for example: 'my_file.py' or any name the user chooses.</li> <li>In the file type these lines:</li> </ol> <pre><code>from mydataviewer.view_dataframe import view_dataframe\nview_dataframe()\n</code></pre> <ol> <li>In a terminal window, navigate to the directory of 'my_file.py'.</li> <li>Type 'python my_file.py', and the package will start.</li> </ol>"},{"location":"mydataviewer-GUI/usage/#c-running-my-dataviewer-from-vs-code","title":"C. Running <code>My DataViewer</code> from VS Code","text":"<p>You can also run the package from VS Code using the terminal.</p> <ol> <li>Open your project in VS Code.</li> <li>Open the integrated terminal by going to View &gt; Terminal.</li> <li>Type the <code>viewdata</code> and press <code>Enter</code>:</li> </ol> <p>This will start the <code>My DataViewer</code> like in a regular terminal.</p>"},{"location":"mydataviewer-GUI/usage/#d-running-my-dataviewer-from-an-exe-file","title":"D. Running <code>My DataViewer</code> from an .exe file","text":"<p>You can also run the package by navigating to <code>Scripts</code> inside the environment in which <code>My DataViewer</code> is insalled.</p> <ol> <li>Navigate to directory <code>C:\\Users\\USER_NAME\\Anaconda3\\envs\\ENV_NAME\\Scripts</code></li> <li>You will find <code>viewdata.exe</code> file, open it.</li> </ol> <p>This will directly start the <code>My DataViewer</code>. The user can also copy the <code>viewdata.exe</code> file to desktop or anyother directory to access it easily.</p>"},{"location":"mydataviewer-GUI/usage/#4-interacting-with-the-my-dataviewer","title":"4. Interacting with the <code>My DataViewer</code>","text":"<p>After running the <code>viewdata</code> command, a data import box will open allowing the user to locate and open the dataframe from <code>Import Dataframe</code> menu. After choosing the dataframe, the <code>My DataViewer</code> GUI window will open, displaying the DataFrame. The window includes:</p> <ul> <li>Table View: Displays the DataFrame in a table format.</li> <li>Sidebar: Shows variable names and data types.</li> <li>Search Bar: Allows you to search within the DataFrame.</li> <li>Interactive Console: An embedded IPython console at the bottom, enabling you to manipulate the DataFrame and reflect the changes in real-time.</li> </ul>"},{"location":"mydataviewer-GUI/usage/#5-customizing-my-dataviewer","title":"5. Customizing <code>My DataViewer</code>","text":"<p>Themes and Fonts - The <code>My DataViewer</code> includes <code>themes</code> and <code>fonts</code> menu options for changing fonts and themes. Access these from the menu bar at the top of the DataViewer window.</p> <p>Themes - Light Theme (Default) - Dark Theme - Solarized Dark Theme - Solarized Light Theme - Monokai Theme - Shades of Purple Theme - Vue Theme</p> <p>Fonts - Arial - Courier New - Times New Roman - Georgia - Verdana - Consolas</p>"},{"location":"mydataviewer-GUI/usage/#watch-my-dataviewer-video-demo","title":"Watch My Dataviewer video demo:","text":""},{"location":"stata_codebook/","title":"Overview","text":""},{"location":"stata_codebook/#stata-codebookpackage","title":"<code>Stata Codebook</code>Package \ud83d\udcca","text":"<p>The <code>stata_codebook</code> package provides tools for generating detailed descriptive statistics and summaries of data frames, similar to Stata's <code>codebook</code> command. <code>codebook</code> command is a very useful command to examine dataset varaibles.  In Stata documentation \"<code>codebook</code> examines the data in producing its results. For variables that codebook thinks are continuous, it presents the mean; the standard deviation; and the 10th, 25th, 50th, 75th, and 90th percentiles. For variables that it thinks are categorical, it presents a tabulation.\".</p> <p>The package supports various features, including: - Summary statistics for numeric and categorical variables - Handling of columns with missing values - Detection of mixed data types - Normality testing with Shapiro-Wilk or Kolmogorov-Smirnov tests, depending on dataset size - Output formatting for academic or professional reports - Check for embedded, leading, and trailing balnks in the variables.</p>"},{"location":"stata_codebook/#why-use-stata_codebook-over-built-in-summary-statistics","title":"Why use stata_codebook over built-in summary statistics?","text":"<p>While pandas offers built-in functions like <code>describe()</code> and <code>value_counts()</code> for summarizing data, the <code>codebook package</code> provides several advantages:</p> <ol> <li> <p>Comprehensive Overview</p> <ul> <li> <p>Numeric and Categorical Data: Unlike <code>describe()</code>, which primarily focuses on numeric data, <code>codebook</code> provides a detailed summary of both numeric and categorical variables. It not only gives you the common statistics like mean, median, and standard deviation but also includes the top categories and their proportions for categorical variables.</p> </li> <li> <p>Handling of Missing Values: The <code>codebook</code> function provides a clear count of missing values for each variable, which is not directly offered by the <code>describe()</code> function.</p> </li> </ul> </li> <li> <p>Data Quality Checks</p> <ul> <li> <p>Detection of Blanks: One of the unique features of the <code>codebook</code> function is its ability to detect embedded, leading, and trailing blanks in string data. This can be crucial for identifying and resolving data entry issues that might otherwise go unnoticed with standard summary statistics.</p> </li> <li> <p>Mixed Data Types: If a column contains mixed data types, the function will automatically detect and handle it, issuing warnings to alert you to potential data quality problems.</p> </li> </ul> </li> <li> <p>Advanced Statistical Insights</p> <ul> <li>Normality Testing: The <code>codebook</code> function includes normality testing (Shapiro-Wilk for small datasets (&lt;5000 observations) and Kolmogorov-Smirnov for large datasets), providing you with p-values that can help you assess the distribution of your numeric data. This goes beyond what the standard <code>describe()</code> function offers.</li> <li>Confidence Intervals: In advanced mode, the function calculates 95% confidence intervals for both numeric variables and the proportions of the top categories in categorical variables, offering deeper insights into your data's variability.</li> </ul> </li> <li> <p>Customizable and Readable Output</p> <ul> <li>Formatted Output: The <code>codebook</code> function rounds numerical results to a specified number of decimal places, ensuring that the output is easy to read and interpret. This is especially valuable for creating reports or presentations where clarity and professionalism are paramount.</li> <li>Consistent Display: By returning a DataFrame with all relevant statistics neatly organized, <code>codebook</code> makes it easier to compare variables side by side, which can be inefficient when using multiple pandas functions.</li> </ul> </li> <li> <p>Easy to Use</p> <ul> <li>Single Command: With just one command, you can generate a detailed and well-rounded summary of one column or the entire DataFrame, saving time and reducing the risk of overlooking important details.</li> </ul> </li> </ol>"},{"location":"stata_codebook/#license","title":"License","text":"<p>Released under the MIT License: For more details, see the <code>LICENSE</code> file. Copyright (C) 2024 <code>stata_codebook</code></p> <p>Developed by: Mohsen Askar ceaser198511@gmail.com</p> <p>Citation</p> <p>If you use Stata Codebook in your research, please cite: <pre><code>@software{stata_codebook2024,\n    title = {AssumptionSheriff: A Python Package for Statistical Assumption Checking},\n    author = {Mohsen Askar},\n    e-mail = {ceaser198511@gmail.com},\n    year = {2024},\n    url = {https://pypi.org/project/stata_codebook/}\n}\n</code></pre></p>"},{"location":"stata_codebook/api/","title":"API Reference","text":""},{"location":"stata_codebook/api/#detailed-function-documentation","title":"Detailed Function Documentation","text":""},{"location":"stata_codebook/api/#function-codebook","title":"Function: <code>codebook</code>","text":"<p>Generates a detailed codebook for a given DataFrame/variable in the dataframe, providing descriptive statistics and data quality checks.</p> <p>Parameters:</p> <ul> <li><code>df</code> (pandas.DataFrame): The DataFrame to analyze.</li> <li><code>column</code> (str, optional): If specified, only this column will be analyzed. Defaults to <code>None</code>.</li> <li><code>advanced</code> (bool, optional): If <code>True</code>, includes additional statistics like standard deviation, confidence intervals, and normality tests. Defaults to <code>False</code>.</li> <li><code>decimal_places</code> (int, optional): The number of decimal places to round numerical results. Defaults to 3.</li> </ul> <p>Returns: - pandas.DataFrame: A DataFrame containing the codebook with descriptive statistics and data quality checks.</p> <p>Example Usage:</p> <pre><code># Generate an advanced codebook for a specific column\ncodebook(df, column='age', advanced=True, decimal_places=2)\n</code></pre> Variable Type Unique values Missing values Blank issues Range 25th percentile 50th percentile (Median) 75th percentile Mean Examples Top categories SD 95% CI Normality test p-value (normality) 0 age float64 4 1 Not applicable (25.0, 40.0) 28.75 32.5 36.25 32.5 [35.0, 25.0, 30.0] - 6.45 (26.18, 38.82) Shapiro-Wilk 0.97"},{"location":"stata_codebook/api/#notes","title":"Notes","text":"<p>If a column contains all missing values, the function will skip detailed analysis for that column and indicate that it is entirely missing. The function automatically handles mixed data types by converting the column to an object type and issuing a warning.</p>"},{"location":"stata_codebook/api/#output-explanation","title":"Output Explanation:","text":"<ul> <li>Variable: The name of the variable.</li> <li>Type: The data type of the variable.</li> <li>Unique values: The number of unique non-null values.</li> <li>Missing values: The number of missing (null) values.</li> <li>Blank issues: Any detected issues with leading, trailing, or embedded blanks in string variables.</li> <li>Range: The minimum and maximum values for numeric variables.</li> <li>25th, 50th, 75th percentile: The respective percentiles for numeric variables.</li> <li>Mean: The mean of numeric variables.</li> <li>SD: The standard deviation for numeric variables (advanced mode).</li> <li>95% CI: The 95% confidence interval for numeric variables (advanced mode).</li> <li>Normality test: The type of normality test applied (Shapiro-Wilk (for datasets with 5000 or fewer observations) or Kolmogorov-Smirnov (for larger datasets)).</li> <li>p-value (normality): The p-value from the normality test.</li> <li>Top categories: The most frequent categories for categorical variables.</li> <li>Top category proportion: The proportion of the top category for categorical variables (advanced mode).</li> <li>95% CI (top category): The 95% confidence interval for the top category proportion (advanced mode).</li> </ul>"},{"location":"stata_codebook/api/#faqtroubleshooting","title":"FAQ/Troubleshooting","text":"<p>Q1: The codebook function isn't working for my DataFrame with mixed data types. What should I do?</p> <p>A: The <code>codebook</code> function automatically detects and converts columns with mixed data types to object (string) type. If you see a warning about mixed types, ensure your data is clean and consistently typed, or allow the function to handle it automatically.</p> <p>Q2: Why does the function skip some columns?</p> <p>A: The function may skip columns if they contain all missing values (<code>NaN</code>). The output will indicate if a column is entirely missing.</p> <p>Q3: How can I adjust the number of decimal places for numerical results?</p> <p>A: You can adjust the decimal precision by setting the <code>decimal_places</code> parameter when calling the <code>codebook</code> function:</p> <p><code>codebook(df, advanced=True, decimal_places=2)</code></p>"},{"location":"stata_codebook/usage/","title":"Usage Guide","text":""},{"location":"stata_codebook/usage/#1-installation","title":"1. Installation","text":"<p>The package can be installed directly from PyPI using pip:</p> <p><code>pip install stata_codebook</code></p>"},{"location":"stata_codebook/usage/#2-quick-start","title":"2. Quick Start","text":"<p>Here's a quick example to get you started:</p> <pre><code>import pandas as pd\nfrom stata_codebook import codebook\n</code></pre> <pre><code># Sample DataFrame\ndata = {\n    'age': [25, 30, 35, 40, None],\n    'income': [50000, 60000, 70000, 80000, 90000],\n    'gender': ['Male', 'Female', 'Female', 'Male', None],\n    'is_employed': [True, True, False, True, None]\n}\ndf = pd.DataFrame(data)\n</code></pre> <pre><code># codebook for all dataset varaibles\ncodebook(df)\n</code></pre> Variable Type Unique values Missing values Blank issues Range 25th percentile 50th percentile (Median) 75th percentile Mean Examples Top categories SD 95% CI Normality test p-value (normality) Top category proportion 95% CI (top category) 0 age float64 4 1 Not applicable (25.0, 40.0) 28.75 32.5 36.25 32.5 [35.0, 25.0, 30.0] - - - - - NaN NaN 1 income int64 5 0 Not applicable (50000, 90000) 60000.0 70000.0 80000.0 70000.0 [70000, 50000, 60000] - - - - - NaN NaN 2 gender object 2 1 No blanks detected - - - - - [Female, Male, Female] {'Male': 2, 'Female': 2} - NaN - - - - 3 is_employed object 2 1 No blanks detected - - - - - [False, True, True] {True: 3, False: 1} - NaN - - - - <pre><code># codebook for specific column in the dataset\ncodebook(df, column='income') # numerical column\n</code></pre> Variable Type Unique values Missing values Blank issues Range 25th percentile 50th percentile (Median) 75th percentile Mean Examples Top categories SD 95% CI Normality test p-value (normality) 0 income int64 5 0 Not applicable (50000, 90000) 60000.0 70000.0 80000.0 70000.0 [70000, 50000, 60000] - - - - - <pre><code># codebook for specific column in the dataset\ncodebook(df, column='gender') # categorical column\n</code></pre> Variable Type Unique values Missing values Blank issues Examples Top categories Range 25th percentile 50th percentile (Median) 75th percentile Mean SD Normality test p-value (normality) Top category proportion 95% CI (top category) 0 gender object 2 1 No blanks detected [Female, Male, Female] {'Male': 2, 'Female': 2} - - - - - - - - - - <pre><code># codebook for specific column in the dataset additional statistics \ncodebook(df, advanced=True)\n</code></pre> Variable Type Unique values Missing values Blank issues Range 25th percentile 50th percentile (Median) 75th percentile Mean Examples Top categories SD 95% CI Normality test p-value (normality) Top category proportion 95% CI (top category) 0 age float64 4 1 Not applicable (25.0, 40.0) 28.75 32.5 36.25 32.5 [35.0, 25.0, 30.0] - 6.455 (26.174, 38.826) Shapiro-Wilk 0.972 NaN NaN 1 income int64 5 0 Not applicable (50000, 90000) 60000.0 70000.0 80000.0 70000.0 [70000, 50000, 60000] - 15811.388 (56140.707, 83859.293) Shapiro-Wilk 0.967 NaN NaN 2 gender object 2 1 No blanks detected - - - - - [Female, Male, Female] {'Male': 2, 'Female': 2} - NaN - - 0.50 (0.01, 0.99) 3 is_employed object 2 1 No blanks detected - - - - - [False, True, True] {True: 3, False: 1} - NaN - - 0.75 (0.326, 1.174)"}]}